{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"LSTM Main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"id":"ZuRnbLnVAdHW","colab_type":"code","outputId":"c6782a6a-31d5-4013-bb9c-e61c62893f65","executionInfo":{"status":"ok","timestamp":1585392944316,"user_tz":-480,"elapsed":4862,"user":{"displayName":"Calvin Chan","photoUrl":"","userId":"13553358647363469990"}},"colab":{"base_uri":"https://localhost:8080/","height":342}},"source":["!pip install tensorflow==1.14.0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OQP2ODmz8YIH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySblhp2H73L1","colab_type":"code","outputId":"a5b7deb7-9985-4340-a5cc-c20664f79cb5","executionInfo":{"status":"ok","timestamp":1585392944325,"user_tz":-480,"elapsed":4798,"user":{"displayName":"Calvin Chan","photoUrl":"","userId":"13553358647363469990"}},"colab":{"base_uri":"https://localhost:8080/","height":505}},"source":["\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","COMP_PATH = \"/content/drive/My Drive/Colab Notebooks/NUS/CS5242 Neural Networks and Deep Learning/Project\"\n","# COMP_PATH = 'C:/Users/moong/Desktop/CS5242 Project/'\n","# COMP_PATH = 'C:\\\\Users\\\\Calvin\\\\Documents\\\\Python Scripts\\\\NUS\\\\CS5242 Neural Networks and Deep Learning\\\\Project'\n","\n","os.chdir(COMP_PATH)\n","os.listdir()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['splits',\n"," 'groundTruth',\n"," 'airplane.png',\n"," 'segment.txt',\n"," 'main.py',\n"," 'data',\n"," '__pycache__',\n"," 'Project CS5242 - Data Exploration.ipynb',\n"," 'model.png',\n"," 'model.json',\n"," 'model.h5',\n"," 'Load Model',\n"," 'All mains',\n"," 'All outputs',\n"," 'Copy of read_datasetBreakfast.py',\n"," 'read_datasetBreakfast.py',\n"," 'start_run.ipynb',\n"," 'Tuning.h5',\n"," 'Tuning.LSTM.h5',\n"," 'tuning_LSTM.output.txt',\n"," 'Tuning_fit_gen.CNNLSTM.cmd.py',\n"," 'Tuning_fit_gen.CNNLSTM.cmd.txt',\n"," 'Tuning_fit_gen.LSTM.cmd.py',\n"," 'Tuning_fit_gen.main.ipynb',\n"," 'loadfile_output.txt',\n"," 'start_run - 2.ipynb',\n"," 'Copy of LSTM Main.ipynb',\n"," 'LSTM Main.ipynb',\n"," 'Copy of start_run - 2.ipynb']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SSFCJOPe9FNW","colab_type":"code","outputId":"bcab4304-9e0b-4ff3-901f-c3ca7efb60be","executionInfo":{"status":"ok","timestamp":1585392951021,"user_tz":-480,"elapsed":11463,"user":{"displayName":"Calvin Chan","photoUrl":"","userId":"13553358647363469990"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["# import main\n","# from read_datasetBreakfast import load_data, read_mapping_dict\n","from read_datasetBreakfast import read_mapping_dict, load_data, get_label_bounds\n","from matplotlib import pyplot as plt\n","import cv2\n","import os\n","import numpy as np\n","import torch\n","\n","from keras.utils import np_utils\n","from keras.callbacks import History \n","\n","from datetime import datetime"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"xsEwDLK79fIx","colab_type":"code","outputId":"8306cb6e-d17e-478e-9b0f-2112d3a566f4","executionInfo":{"status":"ok","timestamp":1585395322997,"user_tz":-480,"elapsed":2383414,"user":{"displayName":"Calvin Chan","photoUrl":"","userId":"13553358647363469990"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["\n","COMP_PATH = \"/content/drive/My Drive/Colab Notebooks/NUS/CS5242 Neural Networks and Deep Learning/Project\"\n","\n","''' \n","training to load train set\n","test to load test set\n","'''\n","split = 'training'\n","#split = 'test'\n","# train_split =  os.path.join(COMP_PATH, 'splits/2 train.split1.bundle') #Train Split\n","# valid_split =  os.path.join(COMP_PATH, 'splits/2 valid.split1.bundle') #Train Split \n","# train_split =  os.path.join(COMP_PATH, 'splits/300 train.split1 - P16_48.bundle') #Train Split\n","# valid_split =  os.path.join(COMP_PATH, 'splits/90 valid.split1 - P49_54.bundle') # Valid Split \n","# train_split =  os.path.join(COMP_PATH, 'splits/900 train.split1 - P16_48.bundle') #Train Split\n","# valid_split =  os.path.join(COMP_PATH, 'splits/150 valid.split1 - P49_54.bundle') # Valid Split \n","train_split =  os.path.join(COMP_PATH, 'splits/train.split1 - Orig.bundle') #Train Split\n","test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n","GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n","DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n","mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n","\n","actions_dict = read_mapping_dict(mapping_loc)\n","if  split == 'training':\n","    startTime = datetime.now()\n","    data_feat, data_labels = load_data( train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n","    labels_uniq, labels_uniq_loc = get_label_bounds(data_labels)\n","    endTime = datetime.now()\n","    print(\"******** Total Time to load file:\",(endTime - startTime))\n","if  split == 'test':\n","    data_feat = load_data( test_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features only\n","\n","# print(len(data_feat))\n","# print(len(data_labels))\n","# print(data_feat)\n","# print(data_labels)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Finish Load the Training data and labels!!!\n","******** Total Time to load file: 0:39:31.804065\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ggE1GNPpcfsK","colab_type":"code","colab":{}},"source":["def add_video_segment(video_segment, segment_label, all_video_segments, all_video_labels, target_len):\n","    video_len = len(video_segment)\n","    if (video_len > 0) and (segment_label != 0):\n","        if (video_len < target_len):\n","            padded_video_segment = np.zeros((target_len, 400))\n","            padded_video_segment[0:len(video_segment)] = video_segment\n","        elif (video_len > target_len):\n","            # Get the middle part\n","            start_idx = (video_len-target_len)//2\n","            padded_video_segment = video_segment[start_idx:start_idx+target_len]\n","        else:\n","            padded_video_segment = video_segment\n","        all_video_segments.append(padded_video_segment)\n","        all_video_labels.append(segment_label)\n","    return all_video_segments, all_video_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CiJ7TTkcl6r","colab_type":"code","colab":{}},"source":["X_data = [data_feat[i].cpu().detach().numpy() for i in range(len(data_feat))]\n","Y_data = data_labels\n","\n","target_len = 50\n","\n","all_video_segments = []\n","all_video_labels = []\n","for i, label_group in enumerate(Y_data):\n","    video_group = X_data[i]\n","    video_segment = []\n","    segment_label = label_group[0]\n","    \n","    idx = 0\n","    for j, label in enumerate(label_group):\n","        \n","        if (label != segment_label):\n","            all_video_segments, all_video_labels = add_video_segment(\n","                video_segment, segment_label, all_video_segments, all_video_labels, target_len)\n","            segment_label = label\n","            video_segment = []\n","            idx = 0\n","        video_segment.append(video_group[j])\n","        idx += 1\n","        if idx == target_len:\n","            all_video_segments, all_video_labels = add_video_segment(\n","                video_segment, segment_label, all_video_segments, all_video_labels, target_len)\n","            video_segment = []\n","            idx = 0\n","\n","    all_video_segments, all_video_labels = add_video_segment(\n","        video_segment, segment_label, all_video_segments, all_video_labels, target_len)\n","        \n","X = np.array(all_video_segments)\n","Y = np.array(all_video_labels)\n","\n","print(X.shape)\n","print(Y.shape)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"psKw1fWWlF2Z","colab_type":"code","colab":{}},"source":["Y = np_utils.to_categorical(Y, num_classes=48)\n","print(Y.shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mkzw_kqy3xMY","colab_type":"code","colab":{}},"source":["n_hidden_nodes = 30\n","n_dense_nodes = 40\n","n_features = 400\n","n_timesteps = target_len\n","n_outputs = 48\n","\n","n_epoch = 100\n","batch_size = 64\n","init_lr = 0.01\n","\n","clipnorm=1.0\n","clipvalue=0.5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OlSunFY-E6E","colab_type":"code","colab":{}},"source":["from keras import optimizers\n","from keras import regularizers\n","\n","# from keras.models import Model, Sequential\n","# from keras.layers import Dense, Flatten, Dropout, LSTM\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Bidirectional\n","import tensorflow as tf\n","\n","\n","lr = tf.compat.v1.train.exponential_decay(\n","    init_lr,                # Base learning rate.\n","    batch_size,  # Current index into the dataset.\n","    8000,          # Decay step.\n","    0.9,                # Decay rate.\n","    staircase=True)\n","\n","adam = optimizers.Adam(lr=lr, clipnorm=clipnorm, clipvalue=clipvalue)\n","\n","\n","\n","model = Sequential()\n","# model.add(Bidirectional(LSTM(n_hidden_nodes, \n","#                              input_shape=(n_timesteps, n_features), \n","#                              kernel_initializer='random_uniform',\n","#                              recurrent_initializer='random_uniform',\n","#                             #  kernel_regularizer=regularizers.l2(0.01), \n","#                             #  recurrent_regularizer=regularizers.l2(0.01) \n","#                              )))\n","# model.add(Bidirectional(LSTM(n_hidden_nodes, input_shape=(n_timesteps, n_features))))\n","model.add(Bidirectional(LSTM(n_hidden_nodes, return_sequences=True, input_shape=(n_timesteps, n_features))))\n","# model.add(Dropout(0.2))\n","model.add(LSTM(20))\n","# model.add(Dropout(0.2))\n","model.add(Dense(n_dense_nodes, activation='relu'))\n","# model.add(Dropout(0.2))\n","# model.add(Dense(200, activation='relu'))\n","model.add(Dense(n_outputs, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)\n","\n","# fit model\n","# print(all_padded_video_segments)\n","# print(all_padded_video_labels)\n","\n","# Split train vs valid data set\n","ratio = 0.9\n","x_train_size = int(X.shape[0]*ratio)\n","x_train = X[:x_train_size]\n","y_train = Y[:x_train_size]\n","x_valid = X[x_train_size:Y.shape[0]]\n","y_valid = Y[x_train_size:Y.shape[0]]\n","\n","print(\"x_train size: \", x_train.shape[0])\n","print(\"x_valid size: \", x_valid.shape[0])\n","\n","\n","history = History()\n","\n","startTime = datetime.now()\n","# for i in range(n_epoch):\n","history = model.fit(X, Y, epochs=n_epoch, batch_size=batch_size, validation_split=0.1, verbose=2, callbacks=[history])\n","endTime = datetime.now()\n","print(\"*** Time took: \"+str(endTime-startTime))\n","    # print(history)\n","#     print('acc %.2f, loss %.2f' % (acc, loss), end='')\n","\n","# for i, video_segment in enumerate(all_padded_video_segments):\n","#     video_segment = np.array(video_segment).reshape(1,n_timesteps,n_features)\n","#     video_label = np.array(one_hot_all_video_labels[i])\n","#     print(video_label.shape)\n","#     model.fit(video_segment, video_label, epochs=1, verbose=1, shuffle=False)\n","    \n","print('\\n# Evaluate on test data')\n","results = model.evaluate(x_valid, y_valid)\n","print('test loss, test acc:', results)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWrDdCDZA9GR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrMM0x2xAdJO","colab_type":"code","colab":{}},"source":["a = []\n","while True:\n","    a.append(\"1\")"],"execution_count":0,"outputs":[]}]}