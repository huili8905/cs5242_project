{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS5242_Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huili8905/cs5242_project/blob/Hui-Li/CS5242_Project%20(version%202).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoRRLvgsWm2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Set-up for Google Drive**\n",
        "\n",
        "---\n",
        "\n",
        "1.   Load Libraries\n",
        "2.   Check GPU Setting\n",
        "3.   Mount Google Drive\n",
        "4.   Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3gvzoLyzx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################\n",
        "#Crash the original RAM to increase to 25GB - if required\n",
        "#################################################\n",
        "a = []\n",
        "while(1):\n",
        "    a.append(\"1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-aUHd9bpAH",
        "colab_type": "code",
        "outputId": "8ed07413-6af2-4fe9-e8ef-57065b592493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "######################\n",
        "1. #Maintain libraries\n",
        "######################\n",
        "#utils\n",
        "from google.colab import drive,files\n",
        "import tarfile\n",
        "\n",
        "#wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import os\n",
        "\n",
        "#pytorch library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "#keras library\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,TimeDistributed,LSTM, Dropout, BatchNormalization\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras import optimizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVPPRD7n1i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtRIdYTPryf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "2. #Check GPU Setting\n",
        "######################\n",
        "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6uikH7KblU1",
        "colab_type": "code",
        "outputId": "10d81ce5-56fe-4fc7-d208-60d87594b840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "######################\n",
        "3. #Mount Google Drive\n",
        "######################\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "115MrHhytxjk",
        "colab_type": "code",
        "outputId": "d2929c4e-756f-4224-b798-08c65184aabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "######################\n",
        "4. #Load Dataset\n",
        "######################\n",
        "#Check default location\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfjdBcWut8Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Update your path to your dataset\n",
        "os.chdir('/gdrive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXWklFmVZkZb",
        "colab_type": "code",
        "outputId": "17a648ca-e9e8-4894-b0a7-8fce192661bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Read read_datasetBreakfast.py from the folder location\n",
        "\n",
        "from read_datasetBreakfast import load_data, read_mapping_dict , get_label_length_seq\n",
        "COMP_PATH = '/gdrive/My Drive/'\n",
        "''' \n",
        "training to load train set\n",
        "test to load test set\n",
        "'''\n",
        "mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
        "actions_dict = read_mapping_dict(mapping_loc)\n",
        "GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
        "DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n",
        "\n",
        "\n",
        "for split in ['training','test']:\n",
        "  if  split == 'training':\n",
        "    train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle') #Train Split\n",
        "    data_feat_train, data_labels, data_labels_loc = load_data(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
        "  if  split == 'test':\n",
        "    test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
        "    data_feat_test = load_data(test_split, actions_dict, GT_folder, DATA_folder, datatype = split)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Load the Training data and labels!!!\n",
            "Finish Load the Test data!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc-MbF5UwVrC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **Data Preparation and Exploration**\n",
        "\n",
        "---\n",
        "\n",
        "1.   Check Data Shape\n",
        "2.   How Much Data\n",
        "3.   No. of Classes\n",
        "4.   Class Distribution (BY VIDEO)\n",
        "5.   Class Distribution (BY FRAME)\n",
        "6.   Get Tensor Data and Labels Ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgS2QPCq8ibe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "1. #Check Data Shape\n",
        "######################\n",
        "\n",
        "print(\"data shape: {} and date type: {}\".format(data_feat_train[0].shape,data_feat_train[0].dtype))\n",
        "print(\"data shape: {} and date type: {}\".format(data_feat_train[1].shape,data_feat_train[0].dtype))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7F9aTy18qbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "2. #How Much Data\n",
        "######################\n",
        "print(\"Number of Training Data: {}\".format(len(data_feat_train)))\n",
        "print(\"Number of Training Data Labels: {}\".format(len(data_labels)))\n",
        "print(\"Number of Test Data: {}\".format(len(data_feat_test)))\n",
        "print(\"% of Test Data: {}\".format(len(data_feat_test)/(len(data_feat_train)+len(data_feat_test))*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIUjnOLzGGAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Unique Labels in each video\n",
        "print(\"Unique Labels in video 0: {} \".format(data_labels[0]))\n",
        "print(\"Frames in video 0: {} \".format(len(data_feat_train[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpObGULa9wzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "3. #No. of class\n",
        "###################### \n",
        "len(actions_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhNo70oU78D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "4. #Class Distribution (BY VIDEO)\n",
        "######################\n",
        "def wrangle_class_distribution(data_label_var , actions_dict):\n",
        "  #check for labels class balance\n",
        "  data_label_var = pd.DataFrame(data_label_var)\n",
        "  data_label_var = pd.DataFrame(data_label_var.unstack(level=0)).reset_index()\n",
        "  data_label_var.drop('level_0',inplace=True,axis=1)\n",
        "  data_label_var.dropna(inplace=True)\n",
        "  data_label_var.columns =['sample_no','cat']\n",
        "  data_label_var['cat'].astype(int)\n",
        "  \n",
        "  #mapping for actions (change keys and values)\n",
        "  actions_dict2 = {y:x for x,y in actions_dict.items()}\n",
        "  data_label_var['cat_name'] = data_label_var['cat'].map(actions_dict2)\n",
        "\n",
        "  return data_label_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKPp9vHT_L6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "sn.set(rc={'figure.figsize':(15.7,8.27)})\n",
        "Train_Class_Dis = wrangle_class_distribution(data_labels , actions_dict)\n",
        "\n",
        "sn.countplot(y= 'cat_name',orient= 'h',data=Train_Class_Dis,order = Train_Class_Dis['cat_name'].value_counts().index)\n",
        "plt.show()\n",
        "\n",
        "#note: no. of unique labels per label in each video"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCo5OmMqH1yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "5. #Class Distribution (BY FRAME)\n",
        "######################\n",
        "def get_frame_breakdown(COMP_PATH):\n",
        "  gt_frame_overall = pd.DataFrame()\n",
        "  for filesname in os.listdir(COMP_PATH+'/groundTruth'):\n",
        "    gt_file_level = pd.read_csv(COMP_PATH+'/groundTruth/'+filesname,header=None)\n",
        "    gt_file_level['file_name'] = filesname\n",
        "    gt_file_level.columns=['cat_name','file_name']\n",
        "    \n",
        "    gt_file_level['cat_no'] = gt_file_level['cat_name'].map(actions_dict)\n",
        "    gt_frame_overall = pd.concat([gt_frame_overall,gt_file_level], sort=False) \n",
        "\n",
        "  return gt_frame_overall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gPSgnJ-J77w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COMP_PATH = '/gdrive/My Drive/'\n",
        "gt_frame_overall = get_frame_breakdown(COMP_PATH)\n",
        "\n",
        "%matplotlib inline\n",
        "sn.set(rc={'figure.figsize':(15.7,8.27)})\n",
        "\n",
        "sn.countplot(y= 'cat_name',orient= 'h',data=gt_frame_overall,order = gt_frame_overall['cat_name'].value_counts().index)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1S4oPg9S2WD",
        "colab_type": "code",
        "outputId": "96dc3eae-b2ac-4ed2-b866-6a39324b7281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "######################\n",
        "6. #Get Tensor Data and Labels Ready\n",
        "######################\n",
        "#get the labels of each frame\n",
        "def get_gt(train_split):\n",
        "   file_ptr = open(train_split, 'r')\n",
        "   content_all = file_ptr.read().split('\\n')[1:-1]\n",
        "   content_all = [x.strip('./data/groundTruth/') + 't' for x in content_all]\n",
        "   all_tasks = ['tea', 'cereals', 'coffee', 'friedegg', 'juice', 'milk', 'sandwich', 'scrambledegg', 'pancake', 'salat']\n",
        "   \n",
        "   labelframe_breakfast = []\n",
        "   labelseq_breakfast = []\n",
        "   labellen_breakfast = []\n",
        "\n",
        "   for content in content_all:\n",
        "     file_ptr = open( GT_folder + content, 'r')\n",
        "     curr_gt = file_ptr.read().split('\\n')[:-1]\n",
        "     curr_gt = list(map(actions_dict.get, curr_gt))\n",
        "\n",
        "     labelframe_breakfast.append(curr_gt)     \n",
        "     label_seq, length_seq = get_label_length_seq(curr_gt)\n",
        "     labelseq_breakfast.append(label_seq)  \n",
        "     #labellen_breakfast.append(length_seq)  \n",
        "\n",
        "   return labelframe_breakfast,labelseq_breakfast\n",
        "\n",
        "labelframe_breakfast ,labelseq_breakfast= get_gt(train_split)\n",
        "\n",
        "print(\"data label len: {} \".format(len(labelframe_breakfast)))\n",
        "print(\"Video 0 data label len: {} \".format(len(labelframe_breakfast[0])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data label len: 1460 \n",
            "Video 0 data label len: 544 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPMtYZggMMBN",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **LSTM / GRU Model**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOIEkpzsXXOo",
        "colab_type": "text"
      },
      "source": [
        "Stratified Sampling /Bootstrapping of frames in each video (if there are too many/little frames) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6XMHlgqvzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3fdbacd-2817-45be-ce71-d06a575bd163"
      },
      "source": [
        "segments = []\n",
        "segment_labels = []\n",
        "segment_len = []\n",
        "N = 800\n",
        "\n",
        "for i, video in enumerate(data_feat_train):\n",
        "  start_idx = min(data_labels_loc[i])\n",
        "  end_idx = max(data_labels_loc[i])\n",
        "  #just to see the length of each video - not required\n",
        "  segment_len_a = (end_idx - start_idx)\n",
        "  segment_len.append(segment_len_a)\n",
        "\n",
        "  if segment_len_a>=N:\n",
        "    #get frames required\n",
        "    #get index for stratified index \n",
        "    stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "    stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "    stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))))).sample(n=N,replace=True).reset_index(drop=True)\n",
        "    stratified_index.sort_values('index',inplace=True)\n",
        "    index_list = list(stratified_index['index'])\n",
        "    \n",
        "    frame = data_feat_train[i][index_list]\n",
        "    frame = np.array(frame)\n",
        "    get_label_list = np.array(labelframe_breakfast[i])\n",
        "    label= get_label_list[index_list]\n",
        "\n",
        "    segments.append(frame)\n",
        "    segment_labels.append(label)\n",
        "\n",
        "  elif segment_len_a < N:\n",
        "    stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "    stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "    stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))),replace=True)).sample(n=N,replace=True).reset_index(drop=True)\n",
        "    stratified_index.sort_values('index',inplace=True)\n",
        "    index_list = list(stratified_index['index'])\n",
        "    \n",
        "    frame = data_feat_train[i][index_list]\n",
        "    frame = np.array(frame)\n",
        "    get_label_list = np.array(labelframe_breakfast[i])\n",
        "    label= get_label_list[index_list]\n",
        "    \n",
        "    segments.append(frame)\n",
        "    segment_labels.append(label)\n",
        "\n",
        "segments = np.array(segments)\n",
        "print(segments.shape)\n",
        "segment_labels = np.array(segment_labels)\n",
        "segment_labels = segment_labels.reshape(1460,N,1)\n",
        "print(segment_labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460, 800, 400)\n",
            "(1460, 800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRUMuBcvDGyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5ac7633-a98a-4891-a695-45f75082996c"
      },
      "source": [
        "# define LSTM configuration\n",
        "n_neurons = 100\n",
        "n_batch_size = 32\n",
        "n_epoch = 100\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(400, 400), return_sequences=True))\n",
        "model.add(LSTM(n_neurons, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=5)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es], validation_split=0.2)\n",
        "model.reset_states()\n",
        "# evaluate\n",
        "result = model.predict(segments, batch_size=n_batch_size, verbose=0)\n",
        "\n",
        "for value in result[0,:,0]:\n",
        "  print('%.1f' % value)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 400, 100)          200400    \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 400, 100)          80400     \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 400, 48)           4848      \n",
            "=================================================================\n",
            "Total params: 285,648\n",
            "Trainable params: 285,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1168/1168 [==============================] - 61s 52ms/step - loss: 3.7632 - sparse_categorical_accuracy: 0.0597 - val_loss: 3.6687 - val_sparse_categorical_accuracy: 0.0960\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.6033 - sparse_categorical_accuracy: 0.1046 - val_loss: 3.5792 - val_sparse_categorical_accuracy: 0.0937\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.5108 - sparse_categorical_accuracy: 0.1067 - val_loss: 3.5202 - val_sparse_categorical_accuracy: 0.0923\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.4463 - sparse_categorical_accuracy: 0.1071 - val_loss: 3.4694 - val_sparse_categorical_accuracy: 0.0970\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.3895 - sparse_categorical_accuracy: 0.1124 - val_loss: 3.4206 - val_sparse_categorical_accuracy: 0.1136\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.3378 - sparse_categorical_accuracy: 0.1311 - val_loss: 3.3752 - val_sparse_categorical_accuracy: 0.1314\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.2997 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.3525 - val_sparse_categorical_accuracy: 0.1435\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.2537 - sparse_categorical_accuracy: 0.1693 - val_loss: 3.3032 - val_sparse_categorical_accuracy: 0.1743\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.2004 - sparse_categorical_accuracy: 0.1934 - val_loss: 3.2494 - val_sparse_categorical_accuracy: 0.1911\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.1480 - sparse_categorical_accuracy: 0.2101 - val_loss: 3.2325 - val_sparse_categorical_accuracy: 0.1919\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.1001 - sparse_categorical_accuracy: 0.2212 - val_loss: 3.1582 - val_sparse_categorical_accuracy: 0.2062\n",
            "Epoch 12/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 3.0437 - sparse_categorical_accuracy: 0.2290 - val_loss: 3.1179 - val_sparse_categorical_accuracy: 0.2134\n",
            "Epoch 13/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.9894 - sparse_categorical_accuracy: 0.2376 - val_loss: 3.0683 - val_sparse_categorical_accuracy: 0.2232\n",
            "Epoch 14/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.9405 - sparse_categorical_accuracy: 0.2451 - val_loss: 3.0381 - val_sparse_categorical_accuracy: 0.2234\n",
            "Epoch 15/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.8835 - sparse_categorical_accuracy: 0.2498 - val_loss: 2.9896 - val_sparse_categorical_accuracy: 0.2305\n",
            "Epoch 16/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.8473 - sparse_categorical_accuracy: 0.2547 - val_loss: 2.9479 - val_sparse_categorical_accuracy: 0.2414\n",
            "Epoch 17/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.7896 - sparse_categorical_accuracy: 0.2651 - val_loss: 2.9367 - val_sparse_categorical_accuracy: 0.2296\n",
            "Epoch 18/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.7609 - sparse_categorical_accuracy: 0.2668 - val_loss: 2.8939 - val_sparse_categorical_accuracy: 0.2452\n",
            "Epoch 19/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.7466 - sparse_categorical_accuracy: 0.2730 - val_loss: 2.9546 - val_sparse_categorical_accuracy: 0.2235\n",
            "Epoch 20/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.7039 - sparse_categorical_accuracy: 0.2761 - val_loss: 2.8683 - val_sparse_categorical_accuracy: 0.2409\n",
            "Epoch 21/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.6630 - sparse_categorical_accuracy: 0.2832 - val_loss: 2.7907 - val_sparse_categorical_accuracy: 0.2567\n",
            "Epoch 22/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.6047 - sparse_categorical_accuracy: 0.2924 - val_loss: 2.7643 - val_sparse_categorical_accuracy: 0.2550\n",
            "Epoch 23/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.5803 - sparse_categorical_accuracy: 0.2991 - val_loss: 2.7469 - val_sparse_categorical_accuracy: 0.2592\n",
            "Epoch 24/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.5531 - sparse_categorical_accuracy: 0.3010 - val_loss: 2.7997 - val_sparse_categorical_accuracy: 0.2485\n",
            "Epoch 25/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.5149 - sparse_categorical_accuracy: 0.3112 - val_loss: 2.6927 - val_sparse_categorical_accuracy: 0.2619\n",
            "Epoch 26/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.5100 - sparse_categorical_accuracy: 0.3103 - val_loss: 2.6687 - val_sparse_categorical_accuracy: 0.2713\n",
            "Epoch 27/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.5098 - sparse_categorical_accuracy: 0.3094 - val_loss: 2.6862 - val_sparse_categorical_accuracy: 0.2605\n",
            "Epoch 28/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.4859 - sparse_categorical_accuracy: 0.3138 - val_loss: 2.7168 - val_sparse_categorical_accuracy: 0.2468\n",
            "Epoch 29/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.4355 - sparse_categorical_accuracy: 0.3228 - val_loss: 2.6377 - val_sparse_categorical_accuracy: 0.2674\n",
            "Epoch 30/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.4224 - sparse_categorical_accuracy: 0.3194 - val_loss: 2.6085 - val_sparse_categorical_accuracy: 0.2772\n",
            "Epoch 31/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3851 - sparse_categorical_accuracy: 0.3360 - val_loss: 2.6628 - val_sparse_categorical_accuracy: 0.2617\n",
            "Epoch 32/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3474 - sparse_categorical_accuracy: 0.3472 - val_loss: 2.7608 - val_sparse_categorical_accuracy: 0.2492\n",
            "Epoch 33/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3713 - sparse_categorical_accuracy: 0.3377 - val_loss: 2.6211 - val_sparse_categorical_accuracy: 0.2749\n",
            "Epoch 34/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3514 - sparse_categorical_accuracy: 0.3379 - val_loss: 2.5793 - val_sparse_categorical_accuracy: 0.2809\n",
            "Epoch 35/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.5189 - sparse_categorical_accuracy: 0.3043 - val_loss: 2.5784 - val_sparse_categorical_accuracy: 0.2944\n",
            "Epoch 36/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3511 - sparse_categorical_accuracy: 0.3398 - val_loss: 2.6137 - val_sparse_categorical_accuracy: 0.2712\n",
            "Epoch 37/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.3033 - sparse_categorical_accuracy: 0.3490 - val_loss: 2.5390 - val_sparse_categorical_accuracy: 0.2771\n",
            "Epoch 38/100\n",
            "1168/1168 [==============================] - 44s 38ms/step - loss: 2.3175 - sparse_categorical_accuracy: 0.3487 - val_loss: 2.6002 - val_sparse_categorical_accuracy: 0.2811\n",
            "Epoch 39/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.2693 - sparse_categorical_accuracy: 0.3560 - val_loss: 3.0942 - val_sparse_categorical_accuracy: 0.1699\n",
            "Epoch 40/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.4068 - sparse_categorical_accuracy: 0.3321 - val_loss: 2.7575 - val_sparse_categorical_accuracy: 0.2605\n",
            "Epoch 41/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.3085 - sparse_categorical_accuracy: 0.3424 - val_loss: 2.5290 - val_sparse_categorical_accuracy: 0.2939\n",
            "Epoch 42/100\n",
            "1168/1168 [==============================] - 44s 37ms/step - loss: 2.2021 - sparse_categorical_accuracy: 0.3691 - val_loss: 2.5048 - val_sparse_categorical_accuracy: 0.2895\n",
            "Epoch 43/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.4035 - sparse_categorical_accuracy: 0.3307 - val_loss: 2.5399 - val_sparse_categorical_accuracy: 0.3008\n",
            "Epoch 44/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.2250 - sparse_categorical_accuracy: 0.3684 - val_loss: 2.4893 - val_sparse_categorical_accuracy: 0.3106\n",
            "Epoch 45/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.2176 - sparse_categorical_accuracy: 0.3721 - val_loss: 2.5026 - val_sparse_categorical_accuracy: 0.3070\n",
            "Epoch 46/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.1621 - sparse_categorical_accuracy: 0.3891 - val_loss: 2.4890 - val_sparse_categorical_accuracy: 0.2981\n",
            "Epoch 47/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.1258 - sparse_categorical_accuracy: 0.3949 - val_loss: 2.4484 - val_sparse_categorical_accuracy: 0.3119\n",
            "Epoch 48/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.1504 - sparse_categorical_accuracy: 0.3933 - val_loss: 2.5334 - val_sparse_categorical_accuracy: 0.3059\n",
            "Epoch 49/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 2.1372 - sparse_categorical_accuracy: 0.3976 - val_loss: 2.5338 - val_sparse_categorical_accuracy: 0.2896\n",
            "Epoch 50/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.0917 - sparse_categorical_accuracy: 0.4041 - val_loss: 2.5214 - val_sparse_categorical_accuracy: 0.3017\n",
            "Epoch 51/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0974 - sparse_categorical_accuracy: 0.4012 - val_loss: 2.4364 - val_sparse_categorical_accuracy: 0.3172\n",
            "Epoch 52/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.4356 - sparse_categorical_accuracy: 0.3253 - val_loss: 2.5380 - val_sparse_categorical_accuracy: 0.2944\n",
            "Epoch 53/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.2193 - sparse_categorical_accuracy: 0.3618 - val_loss: 2.6311 - val_sparse_categorical_accuracy: 0.2750\n",
            "Epoch 54/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.2449 - sparse_categorical_accuracy: 0.3617 - val_loss: 2.6367 - val_sparse_categorical_accuracy: 0.2777\n",
            "Epoch 55/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.1902 - sparse_categorical_accuracy: 0.3750 - val_loss: 2.5951 - val_sparse_categorical_accuracy: 0.2811\n",
            "Epoch 56/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.1434 - sparse_categorical_accuracy: 0.3833 - val_loss: 2.4166 - val_sparse_categorical_accuracy: 0.3171\n",
            "Epoch 57/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0955 - sparse_categorical_accuracy: 0.3971 - val_loss: 2.5034 - val_sparse_categorical_accuracy: 0.3055\n",
            "Epoch 58/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0539 - sparse_categorical_accuracy: 0.4029 - val_loss: 2.8229 - val_sparse_categorical_accuracy: 0.2311\n",
            "Epoch 59/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.1589 - sparse_categorical_accuracy: 0.3856 - val_loss: 2.4044 - val_sparse_categorical_accuracy: 0.3146\n",
            "Epoch 60/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.1229 - sparse_categorical_accuracy: 0.3941 - val_loss: 2.4217 - val_sparse_categorical_accuracy: 0.3204\n",
            "Epoch 61/100\n",
            "1168/1168 [==============================] - 43s 36ms/step - loss: 2.0747 - sparse_categorical_accuracy: 0.4020 - val_loss: 2.3728 - val_sparse_categorical_accuracy: 0.3336\n",
            "Epoch 62/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0354 - sparse_categorical_accuracy: 0.4146 - val_loss: 2.3269 - val_sparse_categorical_accuracy: 0.3309\n",
            "Epoch 63/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0032 - sparse_categorical_accuracy: 0.4230 - val_loss: 2.3420 - val_sparse_categorical_accuracy: 0.3341\n",
            "Epoch 64/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.9859 - sparse_categorical_accuracy: 0.4229 - val_loss: 2.3079 - val_sparse_categorical_accuracy: 0.3471\n",
            "Epoch 65/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0254 - sparse_categorical_accuracy: 0.4196 - val_loss: 2.6584 - val_sparse_categorical_accuracy: 0.2718\n",
            "Epoch 66/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0109 - sparse_categorical_accuracy: 0.4114 - val_loss: 2.3161 - val_sparse_categorical_accuracy: 0.3481\n",
            "Epoch 67/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.9246 - sparse_categorical_accuracy: 0.4344 - val_loss: 2.2385 - val_sparse_categorical_accuracy: 0.3643\n",
            "Epoch 68/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.9010 - sparse_categorical_accuracy: 0.4432 - val_loss: 2.2583 - val_sparse_categorical_accuracy: 0.3599\n",
            "Epoch 69/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.9994 - sparse_categorical_accuracy: 0.4176 - val_loss: 2.2614 - val_sparse_categorical_accuracy: 0.3557\n",
            "Epoch 70/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.8750 - sparse_categorical_accuracy: 0.4509 - val_loss: 2.2305 - val_sparse_categorical_accuracy: 0.3589\n",
            "Epoch 71/100\n",
            "1168/1168 [==============================] - 43s 37ms/step - loss: 1.8942 - sparse_categorical_accuracy: 0.4465 - val_loss: 2.2023 - val_sparse_categorical_accuracy: 0.3691\n",
            "Epoch 72/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.8293 - sparse_categorical_accuracy: 0.4663 - val_loss: 2.2125 - val_sparse_categorical_accuracy: 0.3654\n",
            "Epoch 73/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.8064 - sparse_categorical_accuracy: 0.4651 - val_loss: 2.2101 - val_sparse_categorical_accuracy: 0.3672\n",
            "Epoch 74/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.0419 - sparse_categorical_accuracy: 0.4085 - val_loss: 2.3534 - val_sparse_categorical_accuracy: 0.3308\n",
            "Epoch 75/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 1.8886 - sparse_categorical_accuracy: 0.4491 - val_loss: 2.2275 - val_sparse_categorical_accuracy: 0.3590\n",
            "Epoch 76/100\n",
            "1168/1168 [==============================] - 42s 36ms/step - loss: 2.5235 - sparse_categorical_accuracy: 0.3184 - val_loss: 2.4547 - val_sparse_categorical_accuracy: 0.3067\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0D4cYVdUeNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ba80084-ae37-4125-b18a-f81f2debf4fc"
      },
      "source": [
        "# define LSTM configuration\n",
        "n_neurons = 600\n",
        "n_batch_size = 32\n",
        "n_epoch = 100\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(400, 400),  dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(n_neurons, dropout=0.2, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=5)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es], validation_split=0.2)\n",
        "model.reset_states()\n",
        "# evaluate\n",
        "result = model.predict(segments, batch_size=n_batch_size, verbose=0)\n",
        "\n",
        "for value in result[0,:,0]:\n",
        "  print('%.1f' % value)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_19 (LSTM)               (None, 400, 600)          2402400   \n",
            "_________________________________________________________________\n",
            "lstm_20 (LSTM)               (None, 400, 600)          2882400   \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 400, 48)           28848     \n",
            "=================================================================\n",
            "Total params: 5,313,648\n",
            "Trainable params: 5,313,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 50s 43ms/step - loss: 3.5947 - sparse_categorical_accuracy: 0.1003 - val_loss: 3.3895 - val_sparse_categorical_accuracy: 0.1095\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 3.3254 - sparse_categorical_accuracy: 0.1424 - val_loss: 3.2786 - val_sparse_categorical_accuracy: 0.1562\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 3.2160 - sparse_categorical_accuracy: 0.1778 - val_loss: 3.1684 - val_sparse_categorical_accuracy: 0.1983\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 3.1376 - sparse_categorical_accuracy: 0.1948 - val_loss: 3.0756 - val_sparse_categorical_accuracy: 0.2293\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 3.0495 - sparse_categorical_accuracy: 0.2160 - val_loss: 2.9961 - val_sparse_categorical_accuracy: 0.2310\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 2.9623 - sparse_categorical_accuracy: 0.2275 - val_loss: 2.8901 - val_sparse_categorical_accuracy: 0.2447\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 2.8815 - sparse_categorical_accuracy: 0.2403 - val_loss: 2.8398 - val_sparse_categorical_accuracy: 0.2576\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.8085 - sparse_categorical_accuracy: 0.2556 - val_loss: 2.7752 - val_sparse_categorical_accuracy: 0.2557\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 45s 39ms/step - loss: 2.7487 - sparse_categorical_accuracy: 0.2636 - val_loss: 2.6961 - val_sparse_categorical_accuracy: 0.2585\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.6805 - sparse_categorical_accuracy: 0.2727 - val_loss: 2.6714 - val_sparse_categorical_accuracy: 0.2639\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.6272 - sparse_categorical_accuracy: 0.2792 - val_loss: 2.6155 - val_sparse_categorical_accuracy: 0.2722\n",
            "Epoch 12/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.5749 - sparse_categorical_accuracy: 0.2913 - val_loss: 2.5850 - val_sparse_categorical_accuracy: 0.2739\n",
            "Epoch 13/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 2.5547 - sparse_categorical_accuracy: 0.2966 - val_loss: 2.5516 - val_sparse_categorical_accuracy: 0.2785\n",
            "Epoch 14/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.5112 - sparse_categorical_accuracy: 0.3021 - val_loss: 2.5138 - val_sparse_categorical_accuracy: 0.2836\n",
            "Epoch 15/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.4666 - sparse_categorical_accuracy: 0.3097 - val_loss: 2.4843 - val_sparse_categorical_accuracy: 0.2933\n",
            "Epoch 16/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.4234 - sparse_categorical_accuracy: 0.3202 - val_loss: 2.4415 - val_sparse_categorical_accuracy: 0.2996\n",
            "Epoch 17/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.3976 - sparse_categorical_accuracy: 0.3284 - val_loss: 2.4288 - val_sparse_categorical_accuracy: 0.3073\n",
            "Epoch 18/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 2.3637 - sparse_categorical_accuracy: 0.3304 - val_loss: 2.3974 - val_sparse_categorical_accuracy: 0.3134\n",
            "Epoch 19/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.3440 - sparse_categorical_accuracy: 0.3393 - val_loss: 2.3694 - val_sparse_categorical_accuracy: 0.3159\n",
            "Epoch 20/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 2.2978 - sparse_categorical_accuracy: 0.3439 - val_loss: 2.3775 - val_sparse_categorical_accuracy: 0.3241\n",
            "Epoch 21/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.2723 - sparse_categorical_accuracy: 0.3515 - val_loss: 2.3764 - val_sparse_categorical_accuracy: 0.3173\n",
            "Epoch 22/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.2683 - sparse_categorical_accuracy: 0.3527 - val_loss: 2.3002 - val_sparse_categorical_accuracy: 0.3340\n",
            "Epoch 23/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.2253 - sparse_categorical_accuracy: 0.3679 - val_loss: 2.3432 - val_sparse_categorical_accuracy: 0.3350\n",
            "Epoch 24/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.2135 - sparse_categorical_accuracy: 0.3703 - val_loss: 2.3655 - val_sparse_categorical_accuracy: 0.3373\n",
            "Epoch 25/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.1785 - sparse_categorical_accuracy: 0.3792 - val_loss: 2.2597 - val_sparse_categorical_accuracy: 0.3510\n",
            "Epoch 26/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.1365 - sparse_categorical_accuracy: 0.3814 - val_loss: 2.2495 - val_sparse_categorical_accuracy: 0.3548\n",
            "Epoch 27/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.1096 - sparse_categorical_accuracy: 0.3885 - val_loss: 2.2007 - val_sparse_categorical_accuracy: 0.3670\n",
            "Epoch 28/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.0923 - sparse_categorical_accuracy: 0.3969 - val_loss: 2.2450 - val_sparse_categorical_accuracy: 0.3474\n",
            "Epoch 29/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.0469 - sparse_categorical_accuracy: 0.4089 - val_loss: 2.1626 - val_sparse_categorical_accuracy: 0.3768\n",
            "Epoch 30/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 2.0469 - sparse_categorical_accuracy: 0.4060 - val_loss: 2.2289 - val_sparse_categorical_accuracy: 0.3600\n",
            "Epoch 31/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 2.0444 - sparse_categorical_accuracy: 0.4028 - val_loss: 2.1618 - val_sparse_categorical_accuracy: 0.3703\n",
            "Epoch 32/100\n",
            "1168/1168 [==============================] - 49s 42ms/step - loss: 2.0314 - sparse_categorical_accuracy: 0.4097 - val_loss: 2.1492 - val_sparse_categorical_accuracy: 0.3839\n",
            "Epoch 33/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.0132 - sparse_categorical_accuracy: 0.4133 - val_loss: 2.1382 - val_sparse_categorical_accuracy: 0.3790\n",
            "Epoch 34/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.9876 - sparse_categorical_accuracy: 0.4165 - val_loss: 2.1168 - val_sparse_categorical_accuracy: 0.3992\n",
            "Epoch 35/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.9749 - sparse_categorical_accuracy: 0.4225 - val_loss: 2.0783 - val_sparse_categorical_accuracy: 0.3943\n",
            "Epoch 36/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.9653 - sparse_categorical_accuracy: 0.4268 - val_loss: 2.1021 - val_sparse_categorical_accuracy: 0.3880\n",
            "Epoch 37/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.9062 - sparse_categorical_accuracy: 0.4454 - val_loss: 2.0474 - val_sparse_categorical_accuracy: 0.4069\n",
            "Epoch 38/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.8948 - sparse_categorical_accuracy: 0.4404 - val_loss: 2.0461 - val_sparse_categorical_accuracy: 0.4139\n",
            "Epoch 39/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.8928 - sparse_categorical_accuracy: 0.4465 - val_loss: 2.0059 - val_sparse_categorical_accuracy: 0.4123\n",
            "Epoch 40/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.8663 - sparse_categorical_accuracy: 0.4487 - val_loss: 2.3154 - val_sparse_categorical_accuracy: 0.3730\n",
            "Epoch 41/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.8764 - sparse_categorical_accuracy: 0.4513 - val_loss: 2.3813 - val_sparse_categorical_accuracy: 0.3525\n",
            "Epoch 42/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.8441 - sparse_categorical_accuracy: 0.4534 - val_loss: 2.0046 - val_sparse_categorical_accuracy: 0.4227\n",
            "Epoch 43/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.8270 - sparse_categorical_accuracy: 0.4645 - val_loss: 2.0692 - val_sparse_categorical_accuracy: 0.3998\n",
            "Epoch 44/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 1.8084 - sparse_categorical_accuracy: 0.4652 - val_loss: 1.9723 - val_sparse_categorical_accuracy: 0.4237\n",
            "Epoch 45/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.7536 - sparse_categorical_accuracy: 0.4794 - val_loss: 1.9776 - val_sparse_categorical_accuracy: 0.4261\n",
            "Epoch 46/100\n",
            "1168/1168 [==============================] - 46s 39ms/step - loss: 1.7599 - sparse_categorical_accuracy: 0.4758 - val_loss: 1.9612 - val_sparse_categorical_accuracy: 0.4205\n",
            "Epoch 47/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.7394 - sparse_categorical_accuracy: 0.4840 - val_loss: 1.9516 - val_sparse_categorical_accuracy: 0.4262\n",
            "Epoch 48/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.7279 - sparse_categorical_accuracy: 0.4843 - val_loss: 1.8975 - val_sparse_categorical_accuracy: 0.4388\n",
            "Epoch 49/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.6994 - sparse_categorical_accuracy: 0.4938 - val_loss: 1.9293 - val_sparse_categorical_accuracy: 0.4401\n",
            "Epoch 50/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.7170 - sparse_categorical_accuracy: 0.4924 - val_loss: 1.9371 - val_sparse_categorical_accuracy: 0.4531\n",
            "Epoch 51/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6790 - sparse_categorical_accuracy: 0.4978 - val_loss: 1.9691 - val_sparse_categorical_accuracy: 0.4392\n",
            "Epoch 52/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6728 - sparse_categorical_accuracy: 0.4980 - val_loss: 1.8429 - val_sparse_categorical_accuracy: 0.4558\n",
            "Epoch 53/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.6641 - sparse_categorical_accuracy: 0.5048 - val_loss: 1.9689 - val_sparse_categorical_accuracy: 0.4297\n",
            "Epoch 54/100\n",
            "1168/1168 [==============================] - 47s 41ms/step - loss: 1.7524 - sparse_categorical_accuracy: 0.4823 - val_loss: 1.8271 - val_sparse_categorical_accuracy: 0.4572\n",
            "Epoch 55/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6562 - sparse_categorical_accuracy: 0.5057 - val_loss: 1.9058 - val_sparse_categorical_accuracy: 0.4440\n",
            "Epoch 56/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6237 - sparse_categorical_accuracy: 0.5120 - val_loss: 1.8150 - val_sparse_categorical_accuracy: 0.4661\n",
            "Epoch 57/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5998 - sparse_categorical_accuracy: 0.5244 - val_loss: 1.8827 - val_sparse_categorical_accuracy: 0.4569\n",
            "Epoch 58/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6107 - sparse_categorical_accuracy: 0.5157 - val_loss: 1.8718 - val_sparse_categorical_accuracy: 0.4421\n",
            "Epoch 59/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5856 - sparse_categorical_accuracy: 0.5225 - val_loss: 1.7812 - val_sparse_categorical_accuracy: 0.4742\n",
            "Epoch 60/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5640 - sparse_categorical_accuracy: 0.5252 - val_loss: 1.8699 - val_sparse_categorical_accuracy: 0.4533\n",
            "Epoch 61/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5639 - sparse_categorical_accuracy: 0.5276 - val_loss: 1.8105 - val_sparse_categorical_accuracy: 0.4705\n",
            "Epoch 62/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5283 - sparse_categorical_accuracy: 0.5371 - val_loss: 1.7783 - val_sparse_categorical_accuracy: 0.4767\n",
            "Epoch 63/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5208 - sparse_categorical_accuracy: 0.5401 - val_loss: 1.8685 - val_sparse_categorical_accuracy: 0.4535\n",
            "Epoch 64/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5082 - sparse_categorical_accuracy: 0.5471 - val_loss: 1.9455 - val_sparse_categorical_accuracy: 0.4305\n",
            "Epoch 65/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5404 - sparse_categorical_accuracy: 0.5335 - val_loss: 1.8101 - val_sparse_categorical_accuracy: 0.4595\n",
            "Epoch 66/100\n",
            "1168/1168 [==============================] - 46s 40ms/step - loss: 1.5068 - sparse_categorical_accuracy: 0.5411 - val_loss: 1.8123 - val_sparse_categorical_accuracy: 0.4728\n",
            "Epoch 67/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.5080 - sparse_categorical_accuracy: 0.5429 - val_loss: 1.9308 - val_sparse_categorical_accuracy: 0.4278\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJbLz95BIicx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61e7e614-d423-40ab-c925-baebc907367f"
      },
      "source": [
        "# define LSTM configuration\n",
        "n_neurons = 1000\n",
        "n_batch_size = 32\n",
        "n_epoch = 100\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(400, 400),  dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(n_neurons, dropout=0.2, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=5)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es], validation_split=0.2)\n",
        "model.reset_states()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_21 (LSTM)               (None, 400, 1000)         5604000   \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 400, 1000)         8004000   \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 400, 48)           48048     \n",
            "=================================================================\n",
            "Total params: 13,656,048\n",
            "Trainable params: 13,656,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 53s 45ms/step - loss: 3.5244 - sparse_categorical_accuracy: 0.1157 - val_loss: 3.3123 - val_sparse_categorical_accuracy: 0.1233\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 3.2279 - sparse_categorical_accuracy: 0.1625 - val_loss: 3.1171 - val_sparse_categorical_accuracy: 0.2301\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 3.0827 - sparse_categorical_accuracy: 0.2148 - val_loss: 2.9967 - val_sparse_categorical_accuracy: 0.2442\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.9656 - sparse_categorical_accuracy: 0.2345 - val_loss: 2.8528 - val_sparse_categorical_accuracy: 0.2599\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 49s 42ms/step - loss: 2.8502 - sparse_categorical_accuracy: 0.2515 - val_loss: 2.7689 - val_sparse_categorical_accuracy: 0.2551\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.7497 - sparse_categorical_accuracy: 0.2646 - val_loss: 2.7196 - val_sparse_categorical_accuracy: 0.2626\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.6721 - sparse_categorical_accuracy: 0.2789 - val_loss: 2.6109 - val_sparse_categorical_accuracy: 0.2713\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.6027 - sparse_categorical_accuracy: 0.2842 - val_loss: 2.6001 - val_sparse_categorical_accuracy: 0.2679\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.5437 - sparse_categorical_accuracy: 0.2958 - val_loss: 2.5013 - val_sparse_categorical_accuracy: 0.2963\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 47s 41ms/step - loss: 2.4844 - sparse_categorical_accuracy: 0.3158 - val_loss: 2.4833 - val_sparse_categorical_accuracy: 0.2916\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.4356 - sparse_categorical_accuracy: 0.3219 - val_loss: 2.4932 - val_sparse_categorical_accuracy: 0.2907\n",
            "Epoch 12/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.3870 - sparse_categorical_accuracy: 0.3277 - val_loss: 2.4645 - val_sparse_categorical_accuracy: 0.3026\n",
            "Epoch 13/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.3548 - sparse_categorical_accuracy: 0.3399 - val_loss: 2.4612 - val_sparse_categorical_accuracy: 0.3035\n",
            "Epoch 14/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.2986 - sparse_categorical_accuracy: 0.3586 - val_loss: 2.3470 - val_sparse_categorical_accuracy: 0.3192\n",
            "Epoch 15/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.2778 - sparse_categorical_accuracy: 0.3567 - val_loss: 2.3241 - val_sparse_categorical_accuracy: 0.3384\n",
            "Epoch 16/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.2342 - sparse_categorical_accuracy: 0.3670 - val_loss: 2.2817 - val_sparse_categorical_accuracy: 0.3357\n",
            "Epoch 17/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.1655 - sparse_categorical_accuracy: 0.3865 - val_loss: 2.3194 - val_sparse_categorical_accuracy: 0.3368\n",
            "Epoch 18/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.1513 - sparse_categorical_accuracy: 0.3896 - val_loss: 2.2049 - val_sparse_categorical_accuracy: 0.3506\n",
            "Epoch 19/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.1126 - sparse_categorical_accuracy: 0.3980 - val_loss: 2.2843 - val_sparse_categorical_accuracy: 0.3310\n",
            "Epoch 20/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.0775 - sparse_categorical_accuracy: 0.4069 - val_loss: 2.2237 - val_sparse_categorical_accuracy: 0.3706\n",
            "Epoch 21/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.0582 - sparse_categorical_accuracy: 0.4081 - val_loss: 2.1834 - val_sparse_categorical_accuracy: 0.3752\n",
            "Epoch 22/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 2.0261 - sparse_categorical_accuracy: 0.4187 - val_loss: 2.1891 - val_sparse_categorical_accuracy: 0.3687\n",
            "Epoch 23/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.9786 - sparse_categorical_accuracy: 0.4338 - val_loss: 2.0784 - val_sparse_categorical_accuracy: 0.4055\n",
            "Epoch 24/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.9699 - sparse_categorical_accuracy: 0.4291 - val_loss: 2.1387 - val_sparse_categorical_accuracy: 0.4004\n",
            "Epoch 25/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.9288 - sparse_categorical_accuracy: 0.4402 - val_loss: 2.0633 - val_sparse_categorical_accuracy: 0.4026\n",
            "Epoch 26/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.9114 - sparse_categorical_accuracy: 0.4480 - val_loss: 2.0437 - val_sparse_categorical_accuracy: 0.4016\n",
            "Epoch 27/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.4546 - val_loss: 2.0577 - val_sparse_categorical_accuracy: 0.4001\n",
            "Epoch 28/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.8484 - sparse_categorical_accuracy: 0.4630 - val_loss: 2.1055 - val_sparse_categorical_accuracy: 0.4017\n",
            "Epoch 29/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.8699 - sparse_categorical_accuracy: 0.4551 - val_loss: 2.2559 - val_sparse_categorical_accuracy: 0.3734\n",
            "Epoch 30/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.8163 - sparse_categorical_accuracy: 0.4740 - val_loss: 2.0438 - val_sparse_categorical_accuracy: 0.4141\n",
            "Epoch 31/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.7940 - sparse_categorical_accuracy: 0.4729 - val_loss: 1.9480 - val_sparse_categorical_accuracy: 0.4373\n",
            "Epoch 32/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.7727 - sparse_categorical_accuracy: 0.4809 - val_loss: 2.0159 - val_sparse_categorical_accuracy: 0.4166\n",
            "Epoch 33/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.7479 - sparse_categorical_accuracy: 0.4836 - val_loss: 1.9301 - val_sparse_categorical_accuracy: 0.4466\n",
            "Epoch 34/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.7236 - sparse_categorical_accuracy: 0.4902 - val_loss: 1.9177 - val_sparse_categorical_accuracy: 0.4423\n",
            "Epoch 35/100\n",
            "1168/1168 [==============================] - 47s 41ms/step - loss: 1.7028 - sparse_categorical_accuracy: 0.5020 - val_loss: 1.9040 - val_sparse_categorical_accuracy: 0.4539\n",
            "Epoch 36/100\n",
            "1168/1168 [==============================] - 47s 41ms/step - loss: 1.6765 - sparse_categorical_accuracy: 0.5029 - val_loss: 1.8605 - val_sparse_categorical_accuracy: 0.4568\n",
            "Epoch 37/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.6775 - sparse_categorical_accuracy: 0.5043 - val_loss: 1.9752 - val_sparse_categorical_accuracy: 0.4158\n",
            "Epoch 38/100\n",
            "1168/1168 [==============================] - 48s 41ms/step - loss: 1.6834 - sparse_categorical_accuracy: 0.5040 - val_loss: 1.8693 - val_sparse_categorical_accuracy: 0.4472\n",
            "Epoch 39/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6131 - sparse_categorical_accuracy: 0.5190 - val_loss: 1.9116 - val_sparse_categorical_accuracy: 0.4456\n",
            "Epoch 40/100\n",
            "1168/1168 [==============================] - 47s 40ms/step - loss: 1.6239 - sparse_categorical_accuracy: 0.5133 - val_loss: 2.1277 - val_sparse_categorical_accuracy: 0.4003\n",
            "Epoch 41/100\n",
            "1168/1168 [==============================] - 47s 41ms/step - loss: 1.5887 - sparse_categorical_accuracy: 0.5234 - val_loss: 1.8733 - val_sparse_categorical_accuracy: 0.4541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjqNKQnRw2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "307f1071-e8fe-4b0c-90a0-d45f21f98484"
      },
      "source": [
        "# define LSTM configuration\n",
        "n_neurons = 800\n",
        "n_batch_size = 32\n",
        "n_epoch = 100\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(800, 400), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(n_neurons, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es], validation_split=0.2)\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 800, 800)          3843200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 800, 800)          3200      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 800, 800)          5123200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 800, 800)          3200      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 800, 400)          320400    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 800, 48)           19248     \n",
            "=================================================================\n",
            "Total params: 9,312,448\n",
            "Trainable params: 9,309,248\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1168/1168 [==============================] - 109s 93ms/step - loss: 3.4741 - sparse_categorical_accuracy: 0.1649 - val_loss: 2.9029 - val_sparse_categorical_accuracy: 0.2477\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 89s 76ms/step - loss: 2.6050 - sparse_categorical_accuracy: 0.3135 - val_loss: 2.6068 - val_sparse_categorical_accuracy: 0.2952\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 88s 75ms/step - loss: 2.2733 - sparse_categorical_accuracy: 0.3887 - val_loss: 2.4385 - val_sparse_categorical_accuracy: 0.3298\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 89s 76ms/step - loss: 2.0733 - sparse_categorical_accuracy: 0.4323 - val_loss: 2.3289 - val_sparse_categorical_accuracy: 0.3546\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 89s 76ms/step - loss: 1.9160 - sparse_categorical_accuracy: 0.4764 - val_loss: 2.2953 - val_sparse_categorical_accuracy: 0.3569\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 89s 76ms/step - loss: 1.7907 - sparse_categorical_accuracy: 0.5092 - val_loss: 2.2227 - val_sparse_categorical_accuracy: 0.3706\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 88s 76ms/step - loss: 1.6771 - sparse_categorical_accuracy: 0.5390 - val_loss: 2.1877 - val_sparse_categorical_accuracy: 0.3819\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 89s 76ms/step - loss: 1.5718 - sparse_categorical_accuracy: 0.5686 - val_loss: 2.1590 - val_sparse_categorical_accuracy: 0.3987\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 88s 75ms/step - loss: 1.4946 - sparse_categorical_accuracy: 0.5930 - val_loss: 2.1227 - val_sparse_categorical_accuracy: 0.3998\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 87s 74ms/step - loss: 1.3914 - sparse_categorical_accuracy: 0.6216 - val_loss: 2.1179 - val_sparse_categorical_accuracy: 0.3993\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 88s 76ms/step - loss: 1.3122 - sparse_categorical_accuracy: 0.6456 - val_loss: 2.0796 - val_sparse_categorical_accuracy: 0.4108\n",
            "Epoch 12/100\n",
            " 384/1168 [========>.....................] - ETA: 52s - loss: 1.2194 - sparse_categorical_accuracy: 0.6715"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vVlbId85e5T",
        "colab_type": "text"
      },
      "source": [
        "# Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHPFCTsfP69Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set the variables\n",
        "input_dim = 400\n",
        "hidden_dim = 100\n",
        "n_layers = 2\n",
        "output_dim = 48\n",
        "\n",
        "batch_size = 1  \n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vV5t3JJPCA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNLSTM_test(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,output_dim,n_layers, drop_prob=0.5):\n",
        "    super(RNNLSTM_test, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.n_layers = n_layers\n",
        "\n",
        "    self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first =True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # Initialize hidden state with zeros\n",
        "    h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "    # Initialize cell state\n",
        "    c0 = torch.zeros(self.n_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "    # Set Variable time steps\n",
        "    # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "    # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "    out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "    # Index hidden state of last time step\n",
        "    out = self.fc(out[:, -1, :]) \n",
        "    #out = [self.fc[i](out[:, i, :]) for i in range(seq_dim)]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXcZ9lsMkmHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#init the models and optimizers\n",
        "model =  RNNLSTM_test(input_dim, hidden_dim, n_layers, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "iter = 0\n",
        "for epoch in range(1):\n",
        "  for i in range(len(train_data[0:3])):\n",
        "    seq_dim = len(train_data[i])\n",
        "    images = train_data[i]\n",
        "    labels = train_label[i]\n",
        "    # Reshape Images to 3D\n",
        "    images = images.view(-1, seq_dim, input_dim)\n",
        "    images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
        "\n",
        "    # Change Labels to tensor and reshape\n",
        "    labels = torch.FloatTensor(labels)\n",
        "    labels = labels.view(-1,len(train_label[i]),1)\n",
        "\n",
        "    # Clear gradients w.r.t. parameters\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass to get output/logits\n",
        "    outputs = model(images.float())\n",
        "\n",
        "  # Calculate Loss: softmax --> cross entropy loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    iter += 1\n",
        "\n",
        "    if iter % 500 == 0:\n",
        "        # Calculate Accuracy         \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        # Iterate through test dataset\n",
        "        for images, labels in test_loader:\n",
        "            # Resize image\n",
        "            images = images.view(-1, seq_dim, input_dim)\n",
        "\n",
        "            # Forward pass only to get logits/output\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get predictions from the maximum value\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Total number of labels\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Total correct predictions\n",
        "            correct += (predicted == labels).sum()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        # Print Loss\n",
        "        print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy)) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}