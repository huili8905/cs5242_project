{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS5242_Project_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huili8905/cs5242_project/blob/Hui-Li/CS5242_Project_1_Version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjoRRLvgsWm2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# **Set-up for Google Drive**\n",
        "\n",
        "---\n",
        "\n",
        "1.   Load Libraries\n",
        "2.   Check GPU Setting\n",
        "3.   Mount Google Drive\n",
        "4.   Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3gvzoLyzx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################\n",
        "#Crash the original RAM to increase to 25GB - if required\n",
        "#################################################\n",
        "a = []\n",
        "while(1):\n",
        "    a.append(\"1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu-aUHd9bpAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "1. #Maintain libraries\n",
        "######################\n",
        "#utils\n",
        "from google.colab import drive,files\n",
        "import tarfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "#wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import os\n",
        "\n",
        "#pytorch library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "#keras library\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense,TimeDistributed,LSTM, Dropout, BatchNormalization,AveragePooling1D, MaxPooling1D,GlobalAveragePooling1D, GlobalMaxPooling1D,Input , Conv1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVPPRD7n1i3",
        "colab_type": "code",
        "outputId": "4536244c-9287-4ae7-aa4f-c17c2719e79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgOjNuMNmw3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtRIdYTPryf8",
        "colab_type": "code",
        "outputId": "ea9464c8-c92c-40b8-e5e3-0f3d91178232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######################\n",
        "2. #Check GPU Setting\n",
        "######################\n",
        "torch. device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6uikH7KblU1",
        "colab_type": "code",
        "outputId": "c96731d3-1376-45eb-f429-13cd22b892c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "######################\n",
        "3. #Mount Google Drive\n",
        "######################\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "115MrHhytxjk",
        "colab_type": "code",
        "outputId": "0e7421f1-2b28-4028-876f-8eb380de30d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######################\n",
        "4. #Load Dataset\n",
        "######################\n",
        "#Check default location\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfjdBcWut8Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Update your path to your dataset\n",
        "os.chdir('/gdrive/My Drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXWklFmVZkZb",
        "colab_type": "code",
        "outputId": "a5e3fe5e-f292-43f7-f65f-f51200c1d55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Read read_datasetBreakfast.py from the folder location\n",
        "\n",
        "from read_datasetBreakfast import load_data, read_mapping_dict , get_label_length_seq\n",
        "COMP_PATH = '/gdrive/My Drive/'\n",
        "''' \n",
        "training to load train set\n",
        "test to load test set\n",
        "'''\n",
        "mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
        "actions_dict = read_mapping_dict(mapping_loc)\n",
        "GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
        "DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n",
        "\n",
        "\n",
        "for split in ['training','test']:\n",
        "  if  split == 'training':\n",
        "    train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle') #Train Split\n",
        "    data_feat_train, data_labels, data_labels_loc = load_data(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
        "  if  split == 'test':\n",
        "    test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
        "    data_feat_test = load_data(test_split, actions_dict, GT_folder, DATA_folder, datatype = split)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish Load the Training data and labels!!!\n",
            "Finish Load the Test data!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc-MbF5UwVrC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **Data Preparation and Exploration**\n",
        "\n",
        "---\n",
        "\n",
        "1.   Check Data Shape\n",
        "2.   How Much Data\n",
        "3.   No. of Classes\n",
        "4.   Class Distribution (BY VIDEO)\n",
        "5.   Class Distribution (BY FRAME)\n",
        "6.   Get Tensor Data and Labels Ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgS2QPCq8ibe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "1. #Check Data Shape\n",
        "######################\n",
        "\n",
        "print(\"data shape: {} and date type: {}\".format(data_feat_train[0].shape,data_feat_train[0].dtype))\n",
        "print(\"data shape: {} and date type: {}\".format(data_feat_train[1].shape,data_feat_train[0].dtype))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7F9aTy18qbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "2. #How Much Data\n",
        "######################\n",
        "print(\"Number of Training Data: {}\".format(len(data_feat_train)))\n",
        "print(\"Number of Training Data Labels: {}\".format(len(data_labels)))\n",
        "print(\"Number of Test Data: {}\".format(len(data_feat_test)))\n",
        "print(\"% of Test Data: {}\".format(len(data_feat_test)/(len(data_feat_train)+len(data_feat_test))*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIUjnOLzGGAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Unique Labels in each video\n",
        "print(\"Unique Labels in video 0: {} \".format(data_labels[0]))\n",
        "print(\"Frames in video 0: {} \".format(len(data_feat_train[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpObGULa9wzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "3. #No. of class\n",
        "###################### \n",
        "len(actions_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhNo70oU78D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "4. #Class Distribution (BY VIDEO)\n",
        "######################\n",
        "def wrangle_class_distribution(data_label_var , actions_dict):\n",
        "  #check for labels class balance\n",
        "  data_label_var = pd.DataFrame(data_label_var)\n",
        "  data_label_var = pd.DataFrame(data_label_var.unstack(level=0)).reset_index()\n",
        "  data_label_var.drop('level_0',inplace=True,axis=1)\n",
        "  data_label_var.dropna(inplace=True)\n",
        "  data_label_var.columns =['sample_no','cat']\n",
        "  data_label_var['cat'].astype(int)\n",
        "  \n",
        "  #mapping for actions (change keys and values)\n",
        "  actions_dict2 = {y:x for x,y in actions_dict.items()}\n",
        "  data_label_var['cat_name'] = data_label_var['cat'].map(actions_dict2)\n",
        "\n",
        "  return data_label_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKPp9vHT_L6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "sn.set(rc={'figure.figsize':(15.7,8.27)})\n",
        "Train_Class_Dis = wrangle_class_distribution(data_labels , actions_dict)\n",
        "\n",
        "sn.countplot(y= 'cat_name',orient= 'h',data=Train_Class_Dis,order = Train_Class_Dis['cat_name'].value_counts().index)\n",
        "plt.show()\n",
        "\n",
        "#note: no. of unique labels per label in each video"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCo5OmMqH1yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################\n",
        "5. #Class Distribution (BY FRAME)\n",
        "######################\n",
        "def get_frame_breakdown(COMP_PATH):\n",
        "  gt_frame_overall = pd.DataFrame()\n",
        "  for filesname in os.listdir(COMP_PATH+'/groundTruth'):\n",
        "    gt_file_level = pd.read_csv(COMP_PATH+'/groundTruth/'+filesname,header=None)\n",
        "    gt_file_level['file_name'] = filesname\n",
        "    gt_file_level.columns=['cat_name','file_name']\n",
        "    \n",
        "    gt_file_level['cat_no'] = gt_file_level['cat_name'].map(actions_dict)\n",
        "    gt_frame_overall = pd.concat([gt_frame_overall,gt_file_level], sort=False) \n",
        "\n",
        "  return gt_frame_overall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gPSgnJ-J77w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COMP_PATH = '/gdrive/My Drive/'\n",
        "gt_frame_overall = get_frame_breakdown(COMP_PATH)\n",
        "\n",
        "%matplotlib inline\n",
        "sn.set(rc={'figure.figsize':(15.7,8.27)})\n",
        "\n",
        "sn.countplot(y= 'cat_name',orient= 'h',data=gt_frame_overall,order = gt_frame_overall['cat_name'].value_counts().index)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1S4oPg9S2WD",
        "colab_type": "code",
        "outputId": "f962d021-f4ba-4a36-931b-1edbe932dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "######################\n",
        "6. #Get Tensor Data and Labels Ready\n",
        "######################\n",
        "#get the labels of each frame\n",
        "def get_gt(train_split):\n",
        "   file_ptr = open(train_split, 'r')\n",
        "   content_all = file_ptr.read().split('\\n')[1:-1]\n",
        "   content_all = [x.strip('./data/groundTruth/') + 't' for x in content_all]\n",
        "   all_tasks = ['tea', 'cereals', 'coffee', 'friedegg', 'juice', 'milk', 'sandwich', 'scrambledegg', 'pancake', 'salat']\n",
        "   \n",
        "   labelframe_breakfast = []\n",
        "   labelseq_breakfast = []\n",
        "   labellen_breakfast = []\n",
        "\n",
        "   for content in content_all:\n",
        "     file_ptr = open( GT_folder + content, 'r')\n",
        "     curr_gt = file_ptr.read().split('\\n')[:-1]\n",
        "     curr_gt = list(map(actions_dict.get, curr_gt))\n",
        "\n",
        "     labelframe_breakfast.append(curr_gt)     \n",
        "     label_seq, length_seq = get_label_length_seq(curr_gt)\n",
        "     labelseq_breakfast.append(label_seq)  \n",
        "     #labellen_breakfast.append(length_seq)  \n",
        "\n",
        "   return labelframe_breakfast,labelseq_breakfast\n",
        "\n",
        "labelframe_breakfast ,labelseq_breakfast= get_gt(train_split)\n",
        "\n",
        "print(\"data label len: {} \".format(len(labelframe_breakfast)))\n",
        "print(\"Video 0 data label len: {} \".format(len(labelframe_breakfast[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data label len: 1460 \n",
            "Video 0 data label len: 544 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPMtYZggMMBN",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# **LSTM / GRU Model**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOIEkpzsXXOo",
        "colab_type": "text"
      },
      "source": [
        "Stratified Sampling /Bootstrapping of frames in each video (if there are too many/little frames) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6XMHlgqvzW",
        "colab_type": "code",
        "outputId": "273f7ad5-4e5f-4be2-8517-7a1c1e5acdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "segments = []\n",
        "segment_labels = []\n",
        "segment_len = []\n",
        "N = 800\n",
        "\n",
        "for i, video in enumerate(data_feat_train):\n",
        "  start_idx = min(data_labels_loc[i])\n",
        "  end_idx = max(data_labels_loc[i])\n",
        "  #just to see the length of each video - not required\n",
        "  segment_len_a = (end_idx - start_idx)\n",
        "  segment_len.append(segment_len_a)\n",
        "\n",
        "  if segment_len_a>=N:\n",
        "    #get frames required\n",
        "    #get index for stratified index \n",
        "    stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "    stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "    stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))))).sample(n=N,replace=True).reset_index(drop=True)\n",
        "    stratified_index.sort_values('index',inplace=True)\n",
        "    index_list = list(stratified_index['index'])\n",
        "    \n",
        "    frame = data_feat_train[i][index_list]\n",
        "    frame = np.array(frame)\n",
        "    get_label_list = np.array(labelframe_breakfast[i])\n",
        "    label= get_label_list[index_list]\n",
        "\n",
        "    segments.append(frame)\n",
        "    segment_labels.append(label)\n",
        "\n",
        "  elif segment_len_a < N:\n",
        "    stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "    stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "    stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))),replace=True)).sample(n=N,replace=True).reset_index(drop=True)\n",
        "    stratified_index.sort_values('index',inplace=True)\n",
        "    index_list = list(stratified_index['index'])\n",
        "    \n",
        "    frame = data_feat_train[i][index_list]\n",
        "    frame = np.array(frame)\n",
        "    get_label_list = np.array(labelframe_breakfast[i])\n",
        "    label= get_label_list[index_list]\n",
        "    \n",
        "    segments.append(frame)\n",
        "    segment_labels.append(label)\n",
        "\n",
        "segments = np.array(segments)\n",
        "print(segments.shape)\n",
        "segment_labels = np.array(segment_labels)\n",
        "segment_labels = segment_labels.reshape(1460,N,1)\n",
        "print(segment_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1460, 800, 400)\n",
            "(1460, 800, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIAKDkm0wVfX",
        "colab_type": "code",
        "outputId": "e4336e86-bb32-4888-9d13-202d335dead3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 400\n",
        "n_neurons2 = 1000\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Dense(400, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model2.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "print(model.summary())\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 329s 282ms/step - loss: 3.5716 - sparse_categorical_accuracy: 0.1366 - val_loss: 3.0681 - val_sparse_categorical_accuracy: 0.2242\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.06808, saving model to /model2.hdf5\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 328s 281ms/step - loss: 2.8448 - sparse_categorical_accuracy: 0.2714 - val_loss: 2.8185 - val_sparse_categorical_accuracy: 0.2546\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.06808 to 2.81846, saving model to /model2.hdf5\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 329s 282ms/step - loss: 2.5589 - sparse_categorical_accuracy: 0.3253 - val_loss: 2.6020 - val_sparse_categorical_accuracy: 0.2913\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.81846 to 2.60204, saving model to /model2.hdf5\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 330s 283ms/step - loss: 2.3651 - sparse_categorical_accuracy: 0.3674 - val_loss: 2.5416 - val_sparse_categorical_accuracy: 0.3020\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.60204 to 2.54160, saving model to /model2.hdf5\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 331s 283ms/step - loss: 2.2122 - sparse_categorical_accuracy: 0.4045 - val_loss: 2.4210 - val_sparse_categorical_accuracy: 0.3283\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.54160 to 2.42101, saving model to /model2.hdf5\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 371s 318ms/step - loss: 2.0761 - sparse_categorical_accuracy: 0.4390 - val_loss: 2.3689 - val_sparse_categorical_accuracy: 0.3451\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.42101 to 2.36888, saving model to /model2.hdf5\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 360s 308ms/step - loss: 1.9748 - sparse_categorical_accuracy: 0.4643 - val_loss: 2.3030 - val_sparse_categorical_accuracy: 0.3606\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.36888 to 2.30295, saving model to /model2.hdf5\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 326s 279ms/step - loss: 1.8771 - sparse_categorical_accuracy: 0.4923 - val_loss: 2.2710 - val_sparse_categorical_accuracy: 0.3660\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.30295 to 2.27100, saving model to /model2.hdf5\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 321s 275ms/step - loss: 1.7826 - sparse_categorical_accuracy: 0.5171 - val_loss: 2.1700 - val_sparse_categorical_accuracy: 0.3868\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.27100 to 2.16996, saving model to /model2.hdf5\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 324s 278ms/step - loss: 1.6940 - sparse_categorical_accuracy: 0.5434 - val_loss: 2.1410 - val_sparse_categorical_accuracy: 0.3979\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.16996 to 2.14103, saving model to /model2.hdf5\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 321s 275ms/step - loss: 1.6244 - sparse_categorical_accuracy: 0.5629 - val_loss: 2.0619 - val_sparse_categorical_accuracy: 0.4180\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.14103 to 2.06187, saving model to /model2.hdf5\n",
            "Epoch 12/100\n",
            "1168/1168 [==============================] - 323s 276ms/step - loss: 1.5410 - sparse_categorical_accuracy: 0.5838 - val_loss: 2.0431 - val_sparse_categorical_accuracy: 0.4184\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.06187 to 2.04310, saving model to /model2.hdf5\n",
            "Epoch 13/100\n",
            "1168/1168 [==============================] - 323s 277ms/step - loss: 1.4713 - sparse_categorical_accuracy: 0.6052 - val_loss: 2.0407 - val_sparse_categorical_accuracy: 0.4160\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.04310 to 2.04075, saving model to /model2.hdf5\n",
            "Epoch 14/100\n",
            "1168/1168 [==============================] - 323s 277ms/step - loss: 1.4083 - sparse_categorical_accuracy: 0.6225 - val_loss: 1.9606 - val_sparse_categorical_accuracy: 0.4398\n",
            "\n",
            "Epoch 00014: val_loss improved from 2.04075 to 1.96064, saving model to /model2.hdf5\n",
            "Epoch 15/100\n",
            "1168/1168 [==============================] - 327s 280ms/step - loss: 1.3522 - sparse_categorical_accuracy: 0.6392 - val_loss: 1.9381 - val_sparse_categorical_accuracy: 0.4444\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.96064 to 1.93814, saving model to /model2.hdf5\n",
            "Epoch 16/100\n",
            "1168/1168 [==============================] - 328s 281ms/step - loss: 1.2836 - sparse_categorical_accuracy: 0.6602 - val_loss: 1.9762 - val_sparse_categorical_accuracy: 0.4346\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.93814\n",
            "Epoch 17/100\n",
            "1168/1168 [==============================] - 327s 280ms/step - loss: 1.2426 - sparse_categorical_accuracy: 0.6683 - val_loss: 1.9311 - val_sparse_categorical_accuracy: 0.4433\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.93814 to 1.93111, saving model to /model2.hdf5\n",
            "Epoch 18/100\n",
            "1168/1168 [==============================] - 325s 279ms/step - loss: 1.1850 - sparse_categorical_accuracy: 0.6850 - val_loss: 1.8973 - val_sparse_categorical_accuracy: 0.4536\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.93111 to 1.89727, saving model to /model2.hdf5\n",
            "Epoch 19/100\n",
            "1168/1168 [==============================] - 325s 278ms/step - loss: 1.1355 - sparse_categorical_accuracy: 0.7018 - val_loss: 1.8857 - val_sparse_categorical_accuracy: 0.4600\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.89727 to 1.88568, saving model to /model2.hdf5\n",
            "Epoch 20/100\n",
            "1168/1168 [==============================] - 325s 278ms/step - loss: 1.0952 - sparse_categorical_accuracy: 0.7107 - val_loss: 1.8623 - val_sparse_categorical_accuracy: 0.4592\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.88568 to 1.86232, saving model to /model2.hdf5\n",
            "Epoch 21/100\n",
            "1168/1168 [==============================] - 323s 277ms/step - loss: 1.0395 - sparse_categorical_accuracy: 0.7266 - val_loss: 1.8491 - val_sparse_categorical_accuracy: 0.4667\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.86232 to 1.84907, saving model to /model2.hdf5\n",
            "Epoch 22/100\n",
            "1168/1168 [==============================] - 332s 284ms/step - loss: 1.0126 - sparse_categorical_accuracy: 0.7340 - val_loss: 1.8017 - val_sparse_categorical_accuracy: 0.4777\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.84907 to 1.80165, saving model to /model2.hdf5\n",
            "Epoch 23/100\n",
            "1168/1168 [==============================] - 330s 282ms/step - loss: 0.9732 - sparse_categorical_accuracy: 0.7449 - val_loss: 1.8039 - val_sparse_categorical_accuracy: 0.4781\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.80165\n",
            "Epoch 24/100\n",
            "1168/1168 [==============================] - 333s 285ms/step - loss: 0.9437 - sparse_categorical_accuracy: 0.7531 - val_loss: 1.7771 - val_sparse_categorical_accuracy: 0.4850\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.80165 to 1.77706, saving model to /model2.hdf5\n",
            "Epoch 25/100\n",
            "1168/1168 [==============================] - 331s 284ms/step - loss: 0.8909 - sparse_categorical_accuracy: 0.7680 - val_loss: 1.7702 - val_sparse_categorical_accuracy: 0.4831\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.77706 to 1.77015, saving model to /model2.hdf5\n",
            "Epoch 26/100\n",
            "1168/1168 [==============================] - 334s 286ms/step - loss: 0.8597 - sparse_categorical_accuracy: 0.7765 - val_loss: 1.7616 - val_sparse_categorical_accuracy: 0.4870\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.77015 to 1.76157, saving model to /model2.hdf5\n",
            "Epoch 27/100\n",
            "1168/1168 [==============================] - 335s 287ms/step - loss: 0.8249 - sparse_categorical_accuracy: 0.7879 - val_loss: 1.7574 - val_sparse_categorical_accuracy: 0.4863\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.76157 to 1.75743, saving model to /model2.hdf5\n",
            "Epoch 28/100\n",
            "1168/1168 [==============================] - 331s 284ms/step - loss: 0.7942 - sparse_categorical_accuracy: 0.7935 - val_loss: 1.7075 - val_sparse_categorical_accuracy: 0.5005\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.75743 to 1.70748, saving model to /model2.hdf5\n",
            "Epoch 29/100\n",
            "1168/1168 [==============================] - 316s 271ms/step - loss: 0.7736 - sparse_categorical_accuracy: 0.8003 - val_loss: 1.7199 - val_sparse_categorical_accuracy: 0.4983\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.70748\n",
            "Epoch 30/100\n",
            "1168/1168 [==============================] - 316s 270ms/step - loss: 0.7468 - sparse_categorical_accuracy: 0.8076 - val_loss: 1.6957 - val_sparse_categorical_accuracy: 0.5028\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.70748 to 1.69575, saving model to /model2.hdf5\n",
            "Epoch 31/100\n",
            "1168/1168 [==============================] - 336s 288ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.8141 - val_loss: 1.6980 - val_sparse_categorical_accuracy: 0.5060\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.69575\n",
            "Epoch 32/100\n",
            "1168/1168 [==============================] - 310s 265ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.8204 - val_loss: 1.6918 - val_sparse_categorical_accuracy: 0.5071\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.69575 to 1.69177, saving model to /model2.hdf5\n",
            "Epoch 33/100\n",
            "1168/1168 [==============================] - 308s 264ms/step - loss: 0.6775 - sparse_categorical_accuracy: 0.8263 - val_loss: 1.6886 - val_sparse_categorical_accuracy: 0.5046\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.69177 to 1.68857, saving model to /model2.hdf5\n",
            "Epoch 34/100\n",
            "1168/1168 [==============================] - 308s 264ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.8324 - val_loss: 1.6825 - val_sparse_categorical_accuracy: 0.5081\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.68857 to 1.68253, saving model to /model2.hdf5\n",
            "Epoch 35/100\n",
            "1168/1168 [==============================] - 308s 264ms/step - loss: 0.6370 - sparse_categorical_accuracy: 0.8372 - val_loss: 1.6674 - val_sparse_categorical_accuracy: 0.5097\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.68253 to 1.66738, saving model to /model2.hdf5\n",
            "Epoch 36/100\n",
            "1168/1168 [==============================] - 306s 262ms/step - loss: 0.6163 - sparse_categorical_accuracy: 0.8419 - val_loss: 1.6757 - val_sparse_categorical_accuracy: 0.5113\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.66738\n",
            "Epoch 37/100\n",
            "1168/1168 [==============================] - 322s 276ms/step - loss: 0.5991 - sparse_categorical_accuracy: 0.8480 - val_loss: 1.6711 - val_sparse_categorical_accuracy: 0.5142\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.66738\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 800, 800)          2563200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 800, 800)          3200      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 800, 400)          320400    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 800, 48)           19248     \n",
            "=================================================================\n",
            "Total params: 2,906,048\n",
            "Trainable params: 2,904,448\n",
            "Non-trainable params: 1,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-9v6E368l5l",
        "colab_type": "code",
        "outputId": "f5b79786-78b0-4ced-bd62-6946dc1f84c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 150\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Dense(100, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "adam = optimizers.adam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model3.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "print(model.summary())\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 104s 89ms/step - loss: 3.0918 - sparse_categorical_accuracy: 0.2090 - val_loss: 2.6364 - val_sparse_categorical_accuracy: 0.2749\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.63642, saving model to /model3.hdf5\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 2.2829 - sparse_categorical_accuracy: 0.3580 - val_loss: 2.2894 - val_sparse_categorical_accuracy: 0.3463\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.63642 to 2.28942, saving model to /model3.hdf5\n",
            "Epoch 3/100\n",
            "1150/1168 [============================>.] - ETA: 1s - loss: 1.9379 - sparse_categorical_accuracy: 0.4357\n",
            "Epoch 00003: val_loss improved from 2.28942 to 2.08698, saving model to /model3.hdf5\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.6601 - sparse_categorical_accuracy: 0.5052 - val_loss: 1.9667 - val_sparse_categorical_accuracy: 0.4129\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.08698 to 1.96670, saving model to /model3.hdf5\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.4872 - sparse_categorical_accuracy: 0.5484 - val_loss: 2.0371 - val_sparse_categorical_accuracy: 0.3999\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.96670\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.3359 - sparse_categorical_accuracy: 0.5873 - val_loss: 1.9192 - val_sparse_categorical_accuracy: 0.4368\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.96670 to 1.91915, saving model to /model3.hdf5\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.2329 - sparse_categorical_accuracy: 0.6158 - val_loss: 1.7915 - val_sparse_categorical_accuracy: 0.4714\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.91915 to 1.79153, saving model to /model3.hdf5\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.1477 - sparse_categorical_accuracy: 0.6355 - val_loss: 1.7764 - val_sparse_categorical_accuracy: 0.4865\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.79153 to 1.77642, saving model to /model3.hdf5\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.0860 - sparse_categorical_accuracy: 0.6511 - val_loss: 1.7903 - val_sparse_categorical_accuracy: 0.4814\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.77642\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 102s 87ms/step - loss: 1.0048 - sparse_categorical_accuracy: 0.6769 - val_loss: 1.8233 - val_sparse_categorical_accuracy: 0.4710\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.77642\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_17 (Bidirectio (None, 800, 300)          661200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 800, 300)          1200      \n",
            "_________________________________________________________________\n",
            "time_distributed_30 (TimeDis (None, 800, 100)          30100     \n",
            "_________________________________________________________________\n",
            "time_distributed_31 (TimeDis (None, 800, 48)           4848      \n",
            "=================================================================\n",
            "Total params: 697,348\n",
            "Trainable params: 696,748\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6mb2HdKZRp4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Functional Keras LSTM - with Reshape (Batch * Segment)\n",
        "\n",
        "----------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkShc_ZajtCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_frame_get_label(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx):          \n",
        "  stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "  stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "  stratified_index_df = stratified_index_df[stratified_index_df['index'].isin(list(range(start_idx,end_idx)))]\n",
        "  stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))))).sample(n=N,replace=True).reset_index(drop=True)\n",
        "  stratified_index.sort_values('index',inplace=True)\n",
        "  index_list = list(stratified_index['index'])\n",
        "\n",
        "  frame = data_feat_train[i][index_list]\n",
        "  frame = np.array(frame)\n",
        "  #frame = frame.reshape(1,N*400)\n",
        "\n",
        "  get_label_list = np.array(labelframe_breakfast[i])\n",
        "  label= get_label_list[index_list]\n",
        "  label= np.array(list(set(label)))\n",
        "\n",
        "  return frame,label\n",
        "\n",
        "def get_frame_get_label_replace(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx):\n",
        "  stratified_index_df = pd.DataFrame(labelframe_breakfast[i]).reset_index()\n",
        "  stratified_index_df = stratified_index_df[stratified_index_df[0]!=0]\n",
        "  stratified_index_df = stratified_index_df[stratified_index_df['index'].isin(list(range(start_idx,end_idx)))]\n",
        "  stratified_index = stratified_index_df.groupby(0, group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(stratified_index_df))),replace=True)).sample(n=N,replace=True).reset_index(drop=True)\n",
        "  stratified_index.sort_values('index',inplace=True)\n",
        "  index_list = list(stratified_index['index'])\n",
        "  \n",
        "  frame = data_feat_train[i][index_list]\n",
        "  frame = np.array(frame)\n",
        "  #frame = frame.reshape(1,N*400)\n",
        "\n",
        "  get_label_list = np.array(labelframe_breakfast[i])\n",
        "  label= get_label_list[index_list]\n",
        "  label= np.array(list(set(label)))\n",
        "\n",
        "  \n",
        "  return frame,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWlCUdGRPU-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 200\n",
        "segments = []\n",
        "segment_labels = []\n",
        "\n",
        "def train_gen():\n",
        "  for i, video in tqdm(enumerate(data_feat_train)):\n",
        "    #print(\"start video {}\".format(i))\n",
        "    for k in range(len(data_labels_loc[i])-1):\n",
        "      if len(data_labels_loc[i])==1:\n",
        "        start_idx = data_labels_loc[i][0]\n",
        "        end_idx = len(labelframe_breakfast[i])\n",
        "        len_idx = end_idx- start_idx\n",
        "        print(len_idx)\n",
        "\n",
        "        if  len_idx > N:\n",
        "          frame,label = get_frame_get_label(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx)\n",
        "        elif len_idx < N : \n",
        "          frame,label = get_frame_get_label_replace(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx)\n",
        "\n",
        "\n",
        "      elif len(data_labels_loc[i])>1:\n",
        "        if k==0:\n",
        "          start_idx = data_labels_loc[i][k]\n",
        "        else:\n",
        "          start_idx = data_labels_loc[i][k]+1\n",
        "        end_idx = data_labels_loc[i][k+1]\n",
        "        len_idx = end_idx- start_idx\n",
        "        \n",
        "        if  len_idx> N:\n",
        "          frame,label = get_frame_get_label(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx)\n",
        "        elif len_idx< N : \n",
        "          frame,label = get_frame_get_label_replace(labelframe_breakfast,data_feat_train,i,k,start_idx,end_idx)\n",
        "      \n",
        "      segments.append(frame)\n",
        "      segment_labels.append(label)\n",
        "  \n",
        "  return segments, segment_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okiJmeWSbBDF",
        "colab_type": "code",
        "outputId": "007032f6-13cb-450f-aebb-d223110f95a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "segments, segment_labels =  train_gen()\n",
        "segments = np.array(segments)\n",
        "print(segments.shape)\n",
        "segment_labels = np.array(segment_labels)\n",
        "print(segment_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1460it [01:03, 22.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(6965, 200, 400)\n",
            "(6965, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l6mxitOKvpL",
        "colab_type": "code",
        "outputId": "ed2d51f7-fc02-4001-d786-abf6542881cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_timesteps = segments.shape[1]\n",
        "features = segments.shape[2]\n",
        "n_neurons = 200\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "adam = optimizers.adam(lr=0.0001)\n",
        "\n",
        "inp = Input(shape=(n_timesteps,features))\n",
        "tcl1 = Conv1D(filters=250,\n",
        "               kernel_size=3,\n",
        "               strides=1,\n",
        "               activation='relu')(inp)\n",
        "tcl1 = BatchNormalization()(tcl1)\n",
        "tcl1 = TimeDistributed(Dense(150, activation=\"relu\")) (tcl1)\n",
        "max_pool_bf = MaxPooling1D(pool_size=2)(tcl1)\n",
        "avg_pool_bf = AveragePooling1D(pool_size=2)(tcl1)\n",
        "merge = concatenate([max_pool_bf, avg_pool_bf])\n",
        "\n",
        "lstm = LSTM(n_neurons, return_sequences=True)(merge)\n",
        "lstm = BatchNormalization()(lstm)\n",
        "\n",
        "globalavg_pool = GlobalAveragePooling1D()(lstm)\n",
        "globalmax_pool = GlobalMaxPooling1D()(lstm)\n",
        "merge2 = concatenate([globalavg_pool, globalmax_pool])\n",
        "outp = Dense(300, activation=\"relu\")(merge2)\n",
        "outp = Dropout(0.2)(outp)\n",
        "outp = Dense(150, activation=\"relu\")(outp)\n",
        "outp = Dropout(0.2)(outp)\n",
        "outp = Dense(48, activation=\"softmax\")(outp)\n",
        "model = Model(inputs=inp, outputs=outp)\n",
        "\n",
        "es = EarlyStopping(patience=4)\n",
        "checkpointer = ModelCheckpoint(filepath='/model.hdf5', verbose=1, save_best_only=True)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[checkpointer,es], validation_split=0.2)\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           (None, 200, 400)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 198, 250)     300250      input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 198, 250)     1000        conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_10 (TimeDistri (None, 198, 150)     37650       batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_10 (MaxPooling1D) (None, 99, 150)      0           time_distributed_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_10 (AveragePo (None, 99, 150)      0           time_distributed_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 99, 300)      0           max_pooling1d_10[0][0]           \n",
            "                                                                 average_pooling1d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  (None, 99, 200)      400800      concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 99, 200)      800         lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_16 (Gl (None, 200)          0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_16 (Global (None, 200)          0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 400)          0           global_average_pooling1d_16[0][0]\n",
            "                                                                 global_max_pooling1d_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 300)          120300      concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 300)          0           dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 150)          45150       dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 150)          0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 48)           7248        dropout_24[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 913,198\n",
            "Trainable params: 912,298\n",
            "Non-trainable params: 900\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 5572 samples, validate on 1393 samples\n",
            "Epoch 1/100\n",
            "5572/5572 [==============================] - 83s 15ms/step - loss: 2.8383 - sparse_categorical_accuracy: 0.2457 - val_loss: 2.5602 - val_sparse_categorical_accuracy: 0.2821\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.56016, saving model to /model.hdf5\n",
            "Epoch 2/100\n",
            "5572/5572 [==============================] - 77s 14ms/step - loss: 2.1933 - sparse_categorical_accuracy: 0.3695 - val_loss: 2.4626 - val_sparse_categorical_accuracy: 0.2886\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.56016 to 2.46265, saving model to /model.hdf5\n",
            "Epoch 3/100\n",
            "4800/5572 [========================>.....] - ETA: 9s - loss: 1.9042 - sparse_categorical_accuracy: 0.4231 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxk0fGNPZft1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Archive\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgjqNKQnRw2u",
        "colab_type": "code",
        "outputId": "1fee3901-45a4-4f3b-b5bd-2c22c52a3341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# define LSTM configuration\n",
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 400\n",
        "n_neurons2 = 1000\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(n_neurons2, return_sequences=True))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Dense(400, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "print(model.summary())\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 800, 400)          1281600   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 800, 400)          1600      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 800, 1000)         5604000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 800, 1000)         4000      \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 800, 400)          400400    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 800, 48)           19248     \n",
            "=================================================================\n",
            "Total params: 7,310,848\n",
            "Trainable params: 7,308,048\n",
            "Non-trainable params: 2,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 930s 796ms/step - loss: 3.3346 - sparse_categorical_accuracy: 0.1794 - val_loss: 2.8517 - val_sparse_categorical_accuracy: 0.2573\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.85169, saving model to /model.hdf5\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 868s 743ms/step - loss: 2.5155 - sparse_categorical_accuracy: 0.3271 - val_loss: 2.5404 - val_sparse_categorical_accuracy: 0.3050\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.85169 to 2.54042, saving model to /model.hdf5\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 845s 723ms/step - loss: 2.2142 - sparse_categorical_accuracy: 0.3910 - val_loss: 2.4170 - val_sparse_categorical_accuracy: 0.3373\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.54042 to 2.41704, saving model to /model.hdf5\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 807s 691ms/step - loss: 2.0045 - sparse_categorical_accuracy: 0.4471 - val_loss: 2.2902 - val_sparse_categorical_accuracy: 0.3570\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.41704 to 2.29022, saving model to /model.hdf5\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 847s 725ms/step - loss: 1.8518 - sparse_categorical_accuracy: 0.4844 - val_loss: 2.2167 - val_sparse_categorical_accuracy: 0.3826\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.29022 to 2.21666, saving model to /model.hdf5\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 808s 691ms/step - loss: 1.7155 - sparse_categorical_accuracy: 0.5213 - val_loss: 2.2134 - val_sparse_categorical_accuracy: 0.3809\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.21666 to 2.21340, saving model to /model.hdf5\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 828s 709ms/step - loss: 1.6130 - sparse_categorical_accuracy: 0.5461 - val_loss: 2.1587 - val_sparse_categorical_accuracy: 0.3956\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.21340 to 2.15865, saving model to /model.hdf5\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 873s 747ms/step - loss: 1.5136 - sparse_categorical_accuracy: 0.5746 - val_loss: 2.1530 - val_sparse_categorical_accuracy: 0.3986\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.15865 to 2.15304, saving model to /model.hdf5\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 872s 746ms/step - loss: 1.4040 - sparse_categorical_accuracy: 0.6058 - val_loss: 2.0705 - val_sparse_categorical_accuracy: 0.4132\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.15304 to 2.07052, saving model to /model.hdf5\n",
            "Epoch 10/100\n",
            "1168/1168 [==============================] - 873s 748ms/step - loss: 1.3391 - sparse_categorical_accuracy: 0.6253 - val_loss: 1.9994 - val_sparse_categorical_accuracy: 0.4362\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.07052 to 1.99940, saving model to /model.hdf5\n",
            "Epoch 11/100\n",
            "1168/1168 [==============================] - 861s 737ms/step - loss: 1.2449 - sparse_categorical_accuracy: 0.6514 - val_loss: 2.0154 - val_sparse_categorical_accuracy: 0.4332\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.99940\n",
            "Epoch 12/100\n",
            "1168/1168 [==============================] - 871s 746ms/step - loss: 1.1681 - sparse_categorical_accuracy: 0.6742 - val_loss: 2.0391 - val_sparse_categorical_accuracy: 0.4276\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.99940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beuuRXeEaUR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define LSTM configuration\n",
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 400\n",
        "n_neurons2 = 1000\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(n_neurons2, return_sequences=True))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Dense(400, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['sparse_categorical_accuracy'])\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model2.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "print(model.summary())\n",
        "model.reset_states()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpxlUtyTemSz",
        "colab_type": "code",
        "outputId": "5f4d8577-a5e0-49a4-e034-28f4d5b739dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 400\n",
        "n_neurons2 = 1000\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(TimeDistributed(Dense(400, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "adam = optimizers.adam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model2.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "print(model.summary())\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 327s 280ms/step - loss: 2.7771 - sparse_categorical_accuracy: 0.2650 - val_loss: 2.5890 - val_sparse_categorical_accuracy: 0.2992\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.58904, saving model to /model2.hdf5\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 320s 274ms/step - loss: 1.8730 - sparse_categorical_accuracy: 0.4464 - val_loss: 2.2177 - val_sparse_categorical_accuracy: 0.3656\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.58904 to 2.21771, saving model to /model2.hdf5\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 316s 271ms/step - loss: 1.5304 - sparse_categorical_accuracy: 0.5291 - val_loss: 1.9374 - val_sparse_categorical_accuracy: 0.4393\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.21771 to 1.93742, saving model to /model2.hdf5\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 311s 266ms/step - loss: 1.3269 - sparse_categorical_accuracy: 0.5788 - val_loss: 1.8375 - val_sparse_categorical_accuracy: 0.4476\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.93742 to 1.83748, saving model to /model2.hdf5\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 315s 270ms/step - loss: 1.1782 - sparse_categorical_accuracy: 0.6215 - val_loss: 1.9891 - val_sparse_categorical_accuracy: 0.4328\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.83748\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 316s 270ms/step - loss: 1.0760 - sparse_categorical_accuracy: 0.6501 - val_loss: 1.8686 - val_sparse_categorical_accuracy: 0.4629\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.83748\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_2 (Bidirection (None, 800, 800)          2563200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 800, 800)          3200      \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 800, 400)          320400    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 800, 48)           19248     \n",
            "=================================================================\n",
            "Total params: 2,906,048\n",
            "Trainable params: 2,904,448\n",
            "Non-trainable params: 1,600\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mk827mNk-56",
        "colab_type": "code",
        "outputId": "ef6577a5-e74d-4726-df42-8f06b7c5c8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        }
      },
      "source": [
        "segments_len  = len(segments)\n",
        "n_timesteps = segments[segments_len-1].shape[0]\n",
        "\n",
        "# define LSTM configuration - hyperparameters\n",
        "\n",
        "n_neurons = 200\n",
        "n_neurons2 = 100\n",
        "\n",
        "\n",
        "n_batch_size = 25\n",
        "n_epoch = 100\n",
        "\n",
        "# create LSTM\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_neurons, input_shape=(n_timesteps, 400), return_sequences=True)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(n_neurons2, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(80, activation=\"relu\")))\n",
        "model.add(TimeDistributed(Dense(48, activation=\"softmax\")))\n",
        "\n",
        "adam = optimizers.adam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train LSTM\n",
        "es = EarlyStopping(patience=2)\n",
        "checkpointer = ModelCheckpoint(filepath='/model3.hdf5', verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(segments, segment_labels, epochs=n_epoch, batch_size=n_batch_size, callbacks=[es,checkpointer], validation_split=0.2)\n",
        "print(model.summary())\n",
        "model.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1168 samples, validate on 292 samples\n",
            "Epoch 1/100\n",
            "1168/1168 [==============================] - 130s 112ms/step - loss: 2.9785 - sparse_categorical_accuracy: 0.2290 - val_loss: 2.6086 - val_sparse_categorical_accuracy: 0.2913\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.60861, saving model to /model3.hdf5\n",
            "Epoch 2/100\n",
            "1168/1168 [==============================] - 127s 109ms/step - loss: 2.2163 - sparse_categorical_accuracy: 0.3773 - val_loss: 2.2671 - val_sparse_categorical_accuracy: 0.3477\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.60861 to 2.26714, saving model to /model3.hdf5\n",
            "Epoch 3/100\n",
            "1168/1168 [==============================] - 127s 109ms/step - loss: 1.8497 - sparse_categorical_accuracy: 0.4620 - val_loss: 2.2571 - val_sparse_categorical_accuracy: 0.3723\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.26714 to 2.25713, saving model to /model3.hdf5\n",
            "Epoch 4/100\n",
            "1168/1168 [==============================] - 127s 108ms/step - loss: 1.6222 - sparse_categorical_accuracy: 0.5118 - val_loss: 2.0910 - val_sparse_categorical_accuracy: 0.3861\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.25713 to 2.09101, saving model to /model3.hdf5\n",
            "Epoch 5/100\n",
            "1168/1168 [==============================] - 126s 108ms/step - loss: 1.4729 - sparse_categorical_accuracy: 0.5477 - val_loss: 1.8903 - val_sparse_categorical_accuracy: 0.4378\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.09101 to 1.89026, saving model to /model3.hdf5\n",
            "Epoch 6/100\n",
            "1168/1168 [==============================] - 127s 109ms/step - loss: 1.3337 - sparse_categorical_accuracy: 0.5848 - val_loss: 1.8819 - val_sparse_categorical_accuracy: 0.4450\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.89026 to 1.88188, saving model to /model3.hdf5\n",
            "Epoch 7/100\n",
            "1168/1168 [==============================] - 127s 108ms/step - loss: 1.2273 - sparse_categorical_accuracy: 0.6167 - val_loss: 1.7717 - val_sparse_categorical_accuracy: 0.4740\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.88188 to 1.77170, saving model to /model3.hdf5\n",
            "Epoch 8/100\n",
            "1168/1168 [==============================] - 127s 109ms/step - loss: 1.1418 - sparse_categorical_accuracy: 0.6397 - val_loss: 1.9158 - val_sparse_categorical_accuracy: 0.4422\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.77170\n",
            "Epoch 9/100\n",
            "1168/1168 [==============================] - 127s 109ms/step - loss: 1.0584 - sparse_categorical_accuracy: 0.6671 - val_loss: 1.7906 - val_sparse_categorical_accuracy: 0.4709\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.77170\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_15 (Bidirectio (None, 800, 400)          961600    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 800, 400)          1600      \n",
            "_________________________________________________________________\n",
            "time_distributed_26 (TimeDis (None, 800, 100)          40100     \n",
            "_________________________________________________________________\n",
            "time_distributed_27 (TimeDis (None, 800, 48)           4848      \n",
            "=================================================================\n",
            "Total params: 1,008,148\n",
            "Trainable params: 1,007,348\n",
            "Non-trainable params: 800\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}