{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Action Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device : {}\".format(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_filename = 'data.pickle'\n",
    "\n",
    "# if os.path.isfile(pickle_filename):\n",
    "#     with open(pickle_filename, 'rb') as file:\n",
    "#         train_data_feat, train_data_labels, test_data_feat = pickle.load(file)\n",
    "# else:\n",
    "#     from read_datasetBreakfast import load_data, read_mapping_dict\n",
    "\n",
    "#     COMP_PATH = ''\n",
    "\n",
    "#     ''' \n",
    "#     training to load train set\n",
    "#     test to load test set\n",
    "#     '''\n",
    "#     train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle') #Train Split\n",
    "#     test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
    "#     GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
    "#     DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n",
    "#     mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
    "\n",
    "#     actions_dict = read_mapping_dict(mapping_loc)\n",
    "#     train_data_feat, train_data_labels = load_data( train_split, actions_dict, GT_folder, DATA_folder, datatype = \"training\") #Get features and labels\n",
    "#     test_data_feat = load_data( test_split, actions_dict, GT_folder, DATA_folder, datatype = \"test\") #Get features only\n",
    "    \n",
    "#     with open(pickle_filename, 'wb') as file:\n",
    "#         pickle.dump((train_data_feat, train_data_labels, test_data_feat), file)\n",
    "\n",
    "# print(len(train_data_feat))\n",
    "# print(len(train_data_labels))\n",
    "# print(len(test_data_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(len(train_data_feat))\n",
    "print(len(train_data_labels))\n",
    "print(len(test_data_feat))\n",
    "> 1460\n",
    "> 1460\n",
    "> 252\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"training_segment.txt\", 'r') as file:\n",
    "#     training_segment = [[int(a) for a in line.split()] for line in file]\n",
    "\n",
    "# # tot_segment_len = 0\n",
    "# # n_segment_len = 0\n",
    "# # max_segment_len = 0\n",
    "# # min_segment_len = float(\"inf\")\n",
    "\n",
    "# train_feat_flat = []\n",
    "# train_labels_flat = []\n",
    "# train_flat_idx = []\n",
    "# for video_idx, video_segments in enumerate(tqdm(training_segment)):\n",
    "#     for i in range(len(video_segments)-1):\n",
    "#         segment_len = video_segments[i+1] - video_segments[i]\n",
    "# #         tot_segment_len += segment_len\n",
    "# #         n_segment_len += 1\n",
    "# #         if segment_len > max_segment_len:\n",
    "# #             max_segment_len = segment_len\n",
    "# #         if segment_len < min_segment_len:\n",
    "# #             min_segment_len = segment_len\n",
    "#         train_flat_idx.append(len(train_feat_flat))\n",
    "#         train_feat_flat.extend(train_data_feat[video_idx][video_segments[i]:video_segments[i+1]])\n",
    "#         train_labels_flat.extend([(train_data_labels[video_idx][i])-1]*segment_len)\n",
    "# train_flat_idx.append(len(train_feat_flat))\n",
    "\n",
    "# # avg_segment_len = tot_segment_len / n_segment_len\n",
    "# # print(avg_segment_len, max_segment_len, min_segment_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(avg_segment_len, max_segment_len, min_segment_len)\n",
    "> 404.3518021201413 5791 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle (or load) flatten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d40cb7cde1548248642c2548e1a9386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([2860789, 400])\n",
      "torch.Size([2860789])\n",
      "7076\n",
      "[0, 260, 465, 793, 1054, 1687, 5923, 7216, 7288, 7338]\n"
     ]
    }
   ],
   "source": [
    "num_split = 10\n",
    "load_split = 10\n",
    "\n",
    "files_exist = []\n",
    "for i in range(num_split):\n",
    "    pickle_filename = \"flatten_data_{}.pickle\".format(i)\n",
    "    files_exist.append(os.path.isfile(pickle_filename))\n",
    "\n",
    "if not all(files_exist):\n",
    "    max_len = len(train_feat_flat)\n",
    "    split_len = max_len//num_split\n",
    "    for i in tqdm(range(num_split)):\n",
    "        pickle_filename = \"flatten_data_{}.pickle\".format(i)\n",
    "        start_idx = split_len*i\n",
    "        end_idx = split_len*(i+1) if i < num_split-1 else max_len\n",
    "        print(i, start_idx, end_idx)\n",
    "        with open(pickle_filename, 'wb') as file:\n",
    "            train_feat_split_tensor = torch.stack(train_feat_flat[start_idx:end_idx]).to(dtype=torch.float32)\n",
    "            train_labels_split_tensor = torch.LongTensor(train_labels_flat[start_idx:end_idx])\n",
    "            pickle.dump((train_feat_split_tensor, train_labels_split_tensor), file)\n",
    "    with open(\"flatten_data_idx.txt\", 'w') as file:\n",
    "        for i in train_flat_idx:\n",
    "            file.write(\"{} \".format(i))\n",
    "\n",
    "train_feat_split_list = []\n",
    "train_labels_split_list = []\n",
    "for i in tqdm(range(load_split)):\n",
    "    pickle_filename = \"flatten_data_{}.pickle\".format(i)\n",
    "    with open(pickle_filename, 'rb') as file:\n",
    "        train_feat_split, train_labels_split = pickle.load(file)\n",
    "        train_feat_split_list.append(train_feat_split)\n",
    "        train_labels_split_list.append(train_labels_split)\n",
    "with open(\"flatten_data_idx.txt\", 'r') as file:\n",
    "    train_flat_idx = [int(a) for line in file for a in line.split()]\n",
    "\n",
    "train_feat_tensor = torch.cat(train_feat_split_list, dim=0)\n",
    "train_labels_tensor = torch.cat(train_labels_split_list, dim=0)\n",
    "print(train_feat_tensor.shape)\n",
    "print(train_labels_tensor.shape)\n",
    "print(len(train_flat_idx))\n",
    "print(train_flat_idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([256, 400])\n",
      "<class 'torch.Tensor'> torch.Size([256, 64])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([47, 64])\n",
      "<class 'torch.Tensor'> torch.Size([47])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(400, 64, batch_first=True)\n",
    "        self.linear = nn.Linear(64*3, 47)\n",
    "        self.linear = nn.Linear(64, 47)\n",
    "        self.padding_value = 0\n",
    "    def forward(self, x):\n",
    "        h, (h_last, c) = self.lstm(x)\n",
    "        h_pad, lengths = pad_packed_sequence(h, batch_first=True, padding_value=self.padding_value)\n",
    "        h_avg_pool = torch.sum(h_pad, 1) / torch.sum((h_pad != self.padding_value), 1)\n",
    "        h_max_pool = torch.max(h_pad, 1)[0]\n",
    "        x = torch.cat((h_pad[:,-1], h_avg_pool, h_max_pool), 1)\n",
    "        x = h_max_pool\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "import copy\n",
    "def train_val(num_epoch, dataloader_dict, model, loss, optimizer, print_epoch=True, device=None):\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "    best_acc = 0.0\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        since = time.time()\n",
    "        if print_epoch:\n",
    "            print(\"Epoch {}/{}\".format(epoch+1, num_epoch))\n",
    "            print(\"-----------\")\n",
    "        \n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else :\n",
    "                model.eval()\n",
    "            total_loss = 0.0\n",
    "            total_correct = 0.0\n",
    "            for X, y, batch_len in dataloader_dict[phase]:\n",
    "                if device is not None:\n",
    "                    X = X.to(device)\n",
    "                    y = y.to(device)\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    y_tilde = model(X)\n",
    "                    L = loss(y_tilde, y)\n",
    "                    if phase == \"train\":\n",
    "                        optimizer.zero_grad()\n",
    "                        L.backward()\n",
    "                        optimizer.step()\n",
    "                y_tilde_label = torch.argmax(y_tilde, dim=1)\n",
    "                num_correct = torch.sum((y_tilde_label == y))\n",
    "                \n",
    "                total_loss += L.item() * batch_len\n",
    "                total_correct += num_correct.item()\n",
    "            \n",
    "            epoch_loss = total_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = (total_correct / len(dataloader_dict[phase].dataset)) * 100\n",
    "            \n",
    "            if phase == \"val\":\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            if phase == \"train\":\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_acc_history.append(epoch_acc)\n",
    "\n",
    "            if print_epoch:\n",
    "                print(\"{} | Loss : {:.4f}  Acc : {:.2f}%\".format(phase.capitalize().ljust(5), epoch_loss, epoch_acc))\n",
    "        \n",
    "        print(\"Time elapsed : {:.2f} s\".format(time.time() - since))\n",
    "        print()\n",
    "    \n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model, (val_acc_history, val_loss_history, train_acc_history, train_loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch._utils import _accumulate\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features, labels, indices):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        self.len = len(self.indices) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[self.indices[idx]:self.indices[idx+1]], self.labels[self.indices[idx]])\n",
    "\n",
    "my_dataset = MyDataset(train_feat_tensor, train_labels_tensor, train_flat_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data: 7075\n"
     ]
    }
   ],
   "source": [
    "tot_len = len(my_dataset)\n",
    "print(\"Number of training data: {}\".format(tot_len))\n",
    "\n",
    "train_split_size = 0.8\n",
    "lengths = [int(tot_len*train_split_size), tot_len - int(tot_len*train_split_size)]\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(my_dataset, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch_data):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for feature, label in batch_data:\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    return (pack_sequence(features, enforce_sorted=False), torch.tensor(labels), len(batch_data))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True, collate_fn=collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, pin_memory=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "-----------\n",
      "Train | Loss : 3.4606  Acc : 12.58%\n",
      "Val   | Loss : 3.2393  Acc : 21.84%\n",
      "Time elapsed : 58.49 s\n",
      "\n",
      "Epoch 2/100\n",
      "-----------\n",
      "Train | Loss : 3.0820  Acc : 23.53%\n",
      "Val   | Loss : 2.9384  Acc : 26.01%\n",
      "Time elapsed : 55.47 s\n",
      "\n",
      "Epoch 3/100\n",
      "-----------\n",
      "Train | Loss : 2.7792  Acc : 28.23%\n",
      "Val   | Loss : 2.7036  Acc : 30.88%\n",
      "Time elapsed : 56.19 s\n",
      "\n",
      "Epoch 4/100\n",
      "-----------\n",
      "Train | Loss : 2.5654  Acc : 31.57%\n",
      "Val   | Loss : 2.5176  Acc : 34.56%\n",
      "Time elapsed : 54.89 s\n",
      "\n",
      "Epoch 5/100\n",
      "-----------\n",
      "Train | Loss : 2.3805  Acc : 36.54%\n",
      "Val   | Loss : 2.3407  Acc : 36.54%\n",
      "Time elapsed : 56.80 s\n",
      "\n",
      "Epoch 6/100\n",
      "-----------\n",
      "Train | Loss : 2.2335  Acc : 38.82%\n",
      "Val   | Loss : 2.2434  Acc : 39.29%\n",
      "Time elapsed : 56.49 s\n",
      "\n",
      "Epoch 7/100\n",
      "-----------\n",
      "Train | Loss : 2.1167  Acc : 42.17%\n",
      "Val   | Loss : 2.1715  Acc : 41.27%\n",
      "Time elapsed : 55.46 s\n",
      "\n",
      "Epoch 8/100\n",
      "-----------\n",
      "Train | Loss : 2.0282  Acc : 44.72%\n",
      "Val   | Loss : 2.0901  Acc : 41.91%\n",
      "Time elapsed : 56.03 s\n",
      "\n",
      "Epoch 9/100\n",
      "-----------\n",
      "Train | Loss : 1.9265  Acc : 46.54%\n",
      "Val   | Loss : 2.0078  Acc : 43.60%\n",
      "Time elapsed : 57.86 s\n",
      "\n",
      "Epoch 10/100\n",
      "-----------\n",
      "Train | Loss : 1.8340  Acc : 49.70%\n",
      "Val   | Loss : 1.9468  Acc : 46.78%\n",
      "Time elapsed : 58.42 s\n",
      "\n",
      "Epoch 11/100\n",
      "-----------\n",
      "Train | Loss : 1.7487  Acc : 51.52%\n",
      "Val   | Loss : 1.9013  Acc : 47.07%\n",
      "Time elapsed : 58.83 s\n",
      "\n",
      "Epoch 12/100\n",
      "-----------\n",
      "Train | Loss : 1.6725  Acc : 53.53%\n",
      "Val   | Loss : 1.8563  Acc : 48.48%\n",
      "Time elapsed : 58.36 s\n",
      "\n",
      "Epoch 13/100\n",
      "-----------\n",
      "Train | Loss : 1.6060  Acc : 54.77%\n",
      "Val   | Loss : 1.7878  Acc : 49.61%\n",
      "Time elapsed : 59.52 s\n",
      "\n",
      "Epoch 14/100\n",
      "-----------\n",
      "Train | Loss : 1.5720  Acc : 55.72%\n",
      "Val   | Loss : 1.7802  Acc : 49.82%\n",
      "Time elapsed : 59.51 s\n",
      "\n",
      "Epoch 15/100\n",
      "-----------\n",
      "Train | Loss : 1.4883  Acc : 57.69%\n",
      "Val   | Loss : 1.7505  Acc : 49.33%\n",
      "Time elapsed : 57.88 s\n",
      "\n",
      "Epoch 16/100\n",
      "-----------\n",
      "Train | Loss : 1.4507  Acc : 59.08%\n",
      "Val   | Loss : 1.7367  Acc : 48.48%\n",
      "Time elapsed : 58.48 s\n",
      "\n",
      "Epoch 17/100\n",
      "-----------\n",
      "Train | Loss : 1.4469  Acc : 58.02%\n",
      "Val   | Loss : 1.7521  Acc : 49.12%\n",
      "Time elapsed : 59.30 s\n",
      "\n",
      "Epoch 18/100\n",
      "-----------\n",
      "Train | Loss : 1.4381  Acc : 58.89%\n",
      "Val   | Loss : 1.7161  Acc : 50.04%\n",
      "Time elapsed : 58.45 s\n",
      "\n",
      "Epoch 19/100\n",
      "-----------\n",
      "Train | Loss : 1.3799  Acc : 60.37%\n",
      "Val   | Loss : 1.6807  Acc : 49.54%\n",
      "Time elapsed : 57.59 s\n",
      "\n",
      "Epoch 20/100\n",
      "-----------\n",
      "Train | Loss : 1.3192  Acc : 61.73%\n",
      "Val   | Loss : 1.6870  Acc : 50.53%\n",
      "Time elapsed : 58.90 s\n",
      "\n",
      "Epoch 21/100\n",
      "-----------\n",
      "Train | Loss : 1.2924  Acc : 62.16%\n",
      "Val   | Loss : 1.6842  Acc : 50.04%\n",
      "Time elapsed : 59.11 s\n",
      "\n",
      "Epoch 22/100\n",
      "-----------\n",
      "Train | Loss : 1.2616  Acc : 62.84%\n",
      "Val   | Loss : 1.6529  Acc : 50.46%\n",
      "Time elapsed : 59.44 s\n",
      "\n",
      "Epoch 23/100\n",
      "-----------\n",
      "Train | Loss : 1.2232  Acc : 64.91%\n",
      "Val   | Loss : 1.6520  Acc : 49.68%\n",
      "Time elapsed : 58.07 s\n",
      "\n",
      "Epoch 24/100\n",
      "-----------\n",
      "Train | Loss : 1.1883  Acc : 65.37%\n",
      "Val   | Loss : 1.6571  Acc : 50.67%\n",
      "Time elapsed : 58.90 s\n",
      "\n",
      "Epoch 25/100\n",
      "-----------\n",
      "Train | Loss : 1.1562  Acc : 65.92%\n",
      "Val   | Loss : 1.6024  Acc : 52.16%\n",
      "Time elapsed : 59.60 s\n",
      "\n",
      "Epoch 26/100\n",
      "-----------\n",
      "Train | Loss : 1.1150  Acc : 67.69%\n",
      "Val   | Loss : 1.5926  Acc : 51.94%\n",
      "Time elapsed : 58.16 s\n",
      "\n",
      "Epoch 27/100\n",
      "-----------\n",
      "Train | Loss : 1.0979  Acc : 67.97%\n",
      "Val   | Loss : 1.6076  Acc : 52.86%\n",
      "Time elapsed : 60.38 s\n",
      "\n",
      "Epoch 28/100\n",
      "-----------\n",
      "Train | Loss : 1.0608  Acc : 69.43%\n",
      "Val   | Loss : 1.5756  Acc : 51.87%\n",
      "Time elapsed : 58.81 s\n",
      "\n",
      "Epoch 29/100\n",
      "-----------\n",
      "Train | Loss : 1.0220  Acc : 70.35%\n",
      "Val   | Loss : 1.5577  Acc : 52.86%\n",
      "Time elapsed : 59.89 s\n",
      "\n",
      "Epoch 30/100\n",
      "-----------\n",
      "Train | Loss : 1.0180  Acc : 70.92%\n",
      "Val   | Loss : 1.5840  Acc : 52.01%\n",
      "Time elapsed : 60.58 s\n",
      "\n",
      "Epoch 31/100\n",
      "-----------\n",
      "Train | Loss : 0.9750  Acc : 71.33%\n",
      "Val   | Loss : 1.5684  Acc : 53.85%\n",
      "Time elapsed : 59.51 s\n",
      "\n",
      "Epoch 32/100\n",
      "-----------\n",
      "Train | Loss : 0.9655  Acc : 71.55%\n",
      "Val   | Loss : 1.5738  Acc : 52.30%\n",
      "Time elapsed : 60.76 s\n",
      "\n",
      "Epoch 33/100\n",
      "-----------\n",
      "Train | Loss : 0.9506  Acc : 72.51%\n",
      "Val   | Loss : 1.5508  Acc : 53.07%\n",
      "Time elapsed : 60.14 s\n",
      "\n",
      "Epoch 34/100\n",
      "-----------\n",
      "Train | Loss : 0.9173  Acc : 73.43%\n",
      "Val   | Loss : 1.5607  Acc : 52.44%\n",
      "Time elapsed : 59.58 s\n",
      "\n",
      "Epoch 35/100\n",
      "-----------\n",
      "Train | Loss : 0.8880  Acc : 74.56%\n",
      "Val   | Loss : 1.5492  Acc : 52.51%\n",
      "Time elapsed : 58.90 s\n",
      "\n",
      "Epoch 36/100\n",
      "-----------\n",
      "Train | Loss : 0.8885  Acc : 74.56%\n",
      "Val   | Loss : 1.5393  Acc : 53.64%\n",
      "Time elapsed : 60.07 s\n",
      "\n",
      "Epoch 37/100\n",
      "-----------\n",
      "Train | Loss : 0.8584  Acc : 75.21%\n",
      "Val   | Loss : 1.5737  Acc : 51.31%\n",
      "Time elapsed : 59.26 s\n",
      "\n",
      "Epoch 38/100\n",
      "-----------\n",
      "Train | Loss : 0.8394  Acc : 76.18%\n",
      "Val   | Loss : 1.5335  Acc : 54.20%\n",
      "Time elapsed : 59.87 s\n",
      "\n",
      "Epoch 39/100\n",
      "-----------\n",
      "Train | Loss : 0.8196  Acc : 76.13%\n",
      "Val   | Loss : 1.5607  Acc : 52.44%\n",
      "Time elapsed : 57.68 s\n",
      "\n",
      "Epoch 40/100\n",
      "-----------\n",
      "Train | Loss : 0.8049  Acc : 76.94%\n",
      "Val   | Loss : 1.5625  Acc : 52.37%\n",
      "Time elapsed : 58.53 s\n",
      "\n",
      "Epoch 41/100\n",
      "-----------\n",
      "Train | Loss : 0.7804  Acc : 77.77%\n",
      "Val   | Loss : 1.5517  Acc : 51.94%\n",
      "Time elapsed : 62.00 s\n",
      "\n",
      "Epoch 42/100\n",
      "-----------\n",
      "Train | Loss : 0.7901  Acc : 77.07%\n",
      "Val   | Loss : 1.5533  Acc : 52.37%\n",
      "Time elapsed : 59.62 s\n",
      "\n",
      "Epoch 43/100\n",
      "-----------\n",
      "Train | Loss : 0.7422  Acc : 79.10%\n",
      "Val   | Loss : 1.5489  Acc : 53.14%\n",
      "Time elapsed : 60.12 s\n",
      "\n",
      "Epoch 44/100\n",
      "-----------\n",
      "Train | Loss : 0.7259  Acc : 79.20%\n",
      "Val   | Loss : 1.5595  Acc : 52.58%\n",
      "Time elapsed : 60.35 s\n",
      "\n",
      "Epoch 45/100\n",
      "-----------\n",
      "Train | Loss : 0.7148  Acc : 79.91%\n",
      "Val   | Loss : 1.5741  Acc : 52.65%\n",
      "Time elapsed : 61.13 s\n",
      "\n",
      "Epoch 46/100\n",
      "-----------\n",
      "Train | Loss : 0.7058  Acc : 80.39%\n",
      "Val   | Loss : 1.5386  Acc : 53.00%\n",
      "Time elapsed : 57.37 s\n",
      "\n",
      "Epoch 47/100\n",
      "-----------\n",
      "Train | Loss : 0.6789  Acc : 81.25%\n",
      "Val   | Loss : 1.5329  Acc : 53.50%\n",
      "Time elapsed : 59.03 s\n",
      "\n",
      "Epoch 48/100\n",
      "-----------\n",
      "Train | Loss : 0.6595  Acc : 82.03%\n",
      "Val   | Loss : 1.5500  Acc : 52.23%\n",
      "Time elapsed : 59.21 s\n",
      "\n",
      "Epoch 49/100\n",
      "-----------\n",
      "Train | Loss : 0.6422  Acc : 82.12%\n",
      "Val   | Loss : 1.5439  Acc : 53.64%\n",
      "Time elapsed : 58.56 s\n",
      "\n",
      "Epoch 50/100\n",
      "-----------\n",
      "Train | Loss : 0.6397  Acc : 82.37%\n",
      "Val   | Loss : 1.5493  Acc : 53.78%\n",
      "Time elapsed : 58.92 s\n",
      "\n",
      "Epoch 51/100\n",
      "-----------\n",
      "Train | Loss : 0.6096  Acc : 83.60%\n",
      "Val   | Loss : 1.5451  Acc : 54.28%\n",
      "Time elapsed : 57.09 s\n",
      "\n",
      "Epoch 52/100\n",
      "-----------\n",
      "Train | Loss : 0.5993  Acc : 83.78%\n",
      "Val   | Loss : 1.5425  Acc : 55.41%\n",
      "Time elapsed : 58.09 s\n",
      "\n",
      "Epoch 53/100\n",
      "-----------\n",
      "Train | Loss : 0.5856  Acc : 83.82%\n",
      "Val   | Loss : 1.5802  Acc : 54.98%\n",
      "Time elapsed : 57.19 s\n",
      "\n",
      "Epoch 54/100\n",
      "-----------\n",
      "Train | Loss : 0.5843  Acc : 84.26%\n",
      "Val   | Loss : 1.6035  Acc : 53.07%\n",
      "Time elapsed : 57.95 s\n",
      "\n",
      "Epoch 55/100\n",
      "-----------\n",
      "Train | Loss : 0.5865  Acc : 84.29%\n",
      "Val   | Loss : 1.5705  Acc : 54.42%\n",
      "Time elapsed : 57.81 s\n",
      "\n",
      "Epoch 56/100\n",
      "-----------\n",
      "Train | Loss : 0.5484  Acc : 85.21%\n",
      "Val   | Loss : 1.5773  Acc : 53.00%\n",
      "Time elapsed : 57.52 s\n",
      "\n",
      "Epoch 57/100\n",
      "-----------\n",
      "Train | Loss : 0.5381  Acc : 85.81%\n",
      "Val   | Loss : 1.6119  Acc : 52.65%\n",
      "Time elapsed : 57.86 s\n",
      "\n",
      "Epoch 58/100\n",
      "-----------\n",
      "Train | Loss : 0.5293  Acc : 86.18%\n",
      "Val   | Loss : 1.6024  Acc : 53.07%\n",
      "Time elapsed : 58.47 s\n",
      "\n",
      "Epoch 59/100\n",
      "-----------\n",
      "Train | Loss : 0.5283  Acc : 86.13%\n",
      "Val   | Loss : 1.6012  Acc : 52.86%\n",
      "Time elapsed : 58.41 s\n",
      "\n",
      "Epoch 60/100\n",
      "-----------\n",
      "Train | Loss : 0.5128  Acc : 86.75%\n",
      "Val   | Loss : 1.6135  Acc : 52.51%\n",
      "Time elapsed : 58.24 s\n",
      "\n",
      "Epoch 61/100\n",
      "-----------\n",
      "Train | Loss : 0.4913  Acc : 87.46%\n",
      "Val   | Loss : 1.6229  Acc : 53.50%\n",
      "Time elapsed : 57.98 s\n",
      "\n",
      "Epoch 62/100\n",
      "-----------\n",
      "Train | Loss : 0.4825  Acc : 87.81%\n",
      "Val   | Loss : 1.6156  Acc : 51.52%\n",
      "Time elapsed : 56.60 s\n",
      "\n",
      "Epoch 63/100\n",
      "-----------\n",
      "Train | Loss : 0.4833  Acc : 86.80%\n",
      "Val   | Loss : 1.5982  Acc : 53.36%\n",
      "Time elapsed : 57.34 s\n",
      "\n",
      "Epoch 64/100\n",
      "-----------\n",
      "Train | Loss : 0.4655  Acc : 88.25%\n",
      "Val   | Loss : 1.5898  Acc : 53.43%\n",
      "Time elapsed : 57.39 s\n",
      "\n",
      "Epoch 65/100\n",
      "-----------\n",
      "Train | Loss : 0.4694  Acc : 87.72%\n",
      "Val   | Loss : 1.6276  Acc : 52.93%\n",
      "Time elapsed : 57.51 s\n",
      "\n",
      "Epoch 66/100\n",
      "-----------\n",
      "Train | Loss : 0.4386  Acc : 89.08%\n",
      "Val   | Loss : 1.6079  Acc : 53.57%\n",
      "Time elapsed : 57.27 s\n",
      "\n",
      "Epoch 67/100\n",
      "-----------\n",
      "Train | Loss : 0.4789  Acc : 87.49%\n",
      "Val   | Loss : 1.6531  Acc : 52.58%\n",
      "Time elapsed : 57.13 s\n",
      "\n",
      "Epoch 68/100\n",
      "-----------\n",
      "Train | Loss : 0.4613  Acc : 88.06%\n",
      "Val   | Loss : 1.6640  Acc : 51.45%\n",
      "Time elapsed : 57.65 s\n",
      "\n",
      "Epoch 69/100\n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | Loss : 0.4494  Acc : 88.85%\n",
      "Val   | Loss : 1.6641  Acc : 51.31%\n",
      "Time elapsed : 58.49 s\n",
      "\n",
      "Epoch 70/100\n",
      "-----------\n",
      "Train | Loss : 0.4103  Acc : 90.48%\n",
      "Val   | Loss : 1.6396  Acc : 52.93%\n",
      "Time elapsed : 58.06 s\n",
      "\n",
      "Epoch 71/100\n",
      "-----------\n",
      "Train | Loss : 0.4070  Acc : 90.46%\n",
      "Val   | Loss : 1.6514  Acc : 52.72%\n",
      "Time elapsed : 59.04 s\n",
      "\n",
      "Epoch 72/100\n",
      "-----------\n",
      "Train | Loss : 0.4295  Acc : 89.10%\n",
      "Val   | Loss : 1.6784  Acc : 51.24%\n",
      "Time elapsed : 59.19 s\n",
      "\n",
      "Epoch 73/100\n",
      "-----------\n",
      "Train | Loss : 0.4085  Acc : 89.96%\n",
      "Val   | Loss : 1.6573  Acc : 52.65%\n",
      "Time elapsed : 57.43 s\n",
      "\n",
      "Epoch 74/100\n",
      "-----------\n",
      "Train | Loss : 0.3857  Acc : 91.20%\n",
      "Val   | Loss : 1.6967  Acc : 51.24%\n",
      "Time elapsed : 59.11 s\n",
      "\n",
      "Epoch 75/100\n",
      "-----------\n",
      "Train | Loss : 0.3874  Acc : 90.30%\n",
      "Val   | Loss : 1.6710  Acc : 53.07%\n",
      "Time elapsed : 56.33 s\n",
      "\n",
      "Epoch 76/100\n",
      "-----------\n",
      "Train | Loss : 0.3773  Acc : 91.33%\n",
      "Val   | Loss : 1.6795  Acc : 53.00%\n",
      "Time elapsed : 55.91 s\n",
      "\n",
      "Epoch 77/100\n",
      "-----------\n",
      "Train | Loss : 0.4161  Acc : 88.94%\n",
      "Val   | Loss : 1.7309  Acc : 53.00%\n",
      "Time elapsed : 56.08 s\n",
      "\n",
      "Epoch 78/100\n",
      "-----------\n",
      "Train | Loss : 0.3522  Acc : 92.14%\n",
      "Val   | Loss : 1.7191  Acc : 52.30%\n",
      "Time elapsed : 56.88 s\n",
      "\n",
      "Epoch 79/100\n",
      "-----------\n",
      "Train | Loss : 0.3447  Acc : 92.33%\n",
      "Val   | Loss : 1.6998  Acc : 52.44%\n",
      "Time elapsed : 56.24 s\n",
      "\n",
      "Epoch 80/100\n",
      "-----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-385b1ca60429>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-5eaeca62669c>\u001b[0m in \u001b[0;36mtrain_val\u001b[1;34m(num_epoch, dataloader_dict, model, loss, optimizer, print_epoch, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[0my_tilde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tilde\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nndl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1d4693db524c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_last\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mh_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mh_avg_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_pad\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mh_max_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nndl\\lib\\site-packages\\torch\\nn\\utils\\rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[1;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mbatch_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munsorted_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "my_model = Model()\n",
    "my_model.to(dev)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(my_model.parameters())\n",
    "\n",
    "trained_model, acc = train_val(100, {\"train\": train_loader, \"val\": val_loader}, my_model, loss, optimizer, device=dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
