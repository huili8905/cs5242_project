{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Load the Training data and labels!!!\n",
      "Finish Load the Training data and labels!!!\n"
     ]
    }
   ],
   "source": [
    "from read_datasetBreakfast import load_data, read_mapping_dict, load_data_cust\n",
    "import os\n",
    "import torch\n",
    "import seaborn as sn\n",
    "\n",
    "COMP_PATH = 'C:\\\\Users\\\\cherl\\\\Desktop\\\\Masters\\\\CS5242 Neural Networks and Deep Learning\\\\Project'\n",
    "''' \n",
    "training to load train set\n",
    "test to load test set\n",
    "'''\n",
    "split = 'training'\n",
    "#split = 'test'\n",
    "train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle') #Train Split\n",
    "test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
    "GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
    "DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n",
    "mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
    "\n",
    "actions_dict = read_mapping_dict(mapping_loc)\n",
    "if  split == 'training':\n",
    "    data_feat_train, data_labels = load_data(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
    "    data_feat_train_cust, data_labels_cust = load_data_cust(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
    "if  split == 'test':\n",
    "    data_feat_test = load_data(test_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features only\n",
    "\n",
    "#'''\n",
    "#Write Code Below\n",
    "#Pointers\n",
    "#Need to load the segments.txt file for segments for test videos \n",
    "#Output the CSV in correct format as shown in Evaluation Section\n",
    "#Id corresponds to the segments in order. \n",
    "#Example - 30-150 = Id 0\n",
    "#          150-428 = Id 1\n",
    "#          428-575 = Id 2\n",
    "#Category is the Class of the Predicted Action\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 28\n",
      "Number of Training Data Labels: 28\n",
      "Size of Training Data #0: torch.Size([743, 400])\n",
      "743\n",
      "Testing Data not loaded\n"
     ]
    }
   ],
   "source": [
    "#Print info on the data\n",
    "print(\"Number of Training Data: {}\".format(len(data_feat_train)))\n",
    "print(\"Number of Training Data Labels: {}\".format(len(data_labels)))\n",
    "print(\"Size of Training Data #0: {}\".format(data_feat_train[0].size()))\n",
    "#print(data_feat_train[0][0])\n",
    "print(len(data_labels_cust[0]))\n",
    "#Testing Data\n",
    "try:\n",
    "    print(\"Number of Test Data: {}\".format(len(data_feat_test)))\n",
    "    print(\"% of Training Data: {}\".format(len(data_feat_test)/(len(data_feat_train)+len(data_feat_test))*100))\n",
    "except NameError:\n",
    "    print(\"Testing Data not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([145, 300, 400])\n"
     ]
    }
   ],
   "source": [
    "#Preparing the data by splitting video into segments\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "segments = []\n",
    "segment_labels = []\n",
    "for i, video in enumerate(data_feat_train):\n",
    "    frame_num = 0\n",
    "    while frame_num < len(video):\n",
    "        #Skip SIL frames\n",
    "        if data_labels_cust[i][frame_num] > 0:\n",
    "            start_index = frame_num # start index of segment\n",
    "            end_index = frame_num # end index of segment\n",
    "            start_label = data_labels_cust[i][frame_num] # label of segment\n",
    "            for index in range(start_index + 1, len(video)):\n",
    "                if data_labels_cust[i][index] == start_label:\n",
    "                    frame_num=index + 1\n",
    "                    end_index=index\n",
    "                else:\n",
    "                    frame_num=index + 1\n",
    "                    break\n",
    "            segment = video[start_index:end_index]\n",
    "            segments.append(segment)\n",
    "            segment_label = []\n",
    "            segment_label.append(start_label)\n",
    "            segment_labels.append(segment_label)\n",
    "            #print(segment.size())\n",
    "            #print(\"start {}, end {}\".format(start_index, end_index))\n",
    "        else:\n",
    "            frame_num += 1\n",
    "#print(segment_labels)\n",
    "\n",
    "# Making all the segments equal length\n",
    "standardized_segments = []\n",
    "target_segment_length = 300 # Standard length to convert all segments to. Tune as needed.\n",
    "\n",
    "for segment in segments:\n",
    "    if len(segment) > target_segment_length:\n",
    "        # Truncate segment\n",
    "        standardized_segment = segment[0:target_segment_length]\n",
    "        standardized_segments.append(standardized_segment.float())\n",
    "    elif len(segment) == target_segment_length:\n",
    "        standardized_segment = segment\n",
    "        standardized_segments.append(standardized_segment.float())\n",
    "    else:\n",
    "        # Pad segment\n",
    "        standardized_segment = torch.zeros(target_segment_length, 400)\n",
    "        standardized_segment[0:len(segment)] = segment\n",
    "        standardized_segments.append(standardized_segment.float())\n",
    "    #print(standardized_segment.size())\n",
    "    \n",
    "# Creating data loaders from data\n",
    "batch_size = 10\n",
    "train_valid_split = 100\n",
    "valid_end = 140\n",
    "standardized_segments_tensor = torch.stack(standardized_segments)\n",
    "print(standardized_segments_tensor.shape)\n",
    "segment_labels_tensor = torch.tensor(segment_labels)\n",
    "\n",
    "train_data = TensorDataset(standardized_segments_tensor[:train_valid_split], segment_labels_tensor[:train_valid_split])\n",
    "valid_data = TensorDataset(standardized_segments_tensor[train_valid_split:valid_end], segment_labels_tensor[train_valid_split:valid_end])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "#print(next(enumerate(train_loader)))\n",
    "#print(next(enumerate(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define the neural network modules\n",
    "\n",
    "class mynet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mynet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 10, stride=5).double()\n",
    "        self.pool = nn.MaxPool2d(5, stride=5).double()\n",
    "        self.fc1 = nn.Linear(target_segment_length * 16, 47).double()\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class myGruNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(myGruNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    #Initialize the hidden layer\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "class myRnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size, n_layers=1):\n",
    "        super(myRnn, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "         \n",
    "        batch_size = input.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "    \n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers   # number of LSTM layers \n",
    "        self.hidden_dim = hidden_dim   # number of hidden nodes in LSTM\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward (self, input):\n",
    "        \n",
    "        lstm_out, h = self.lstm(input)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        #print(\"FC shape : {}\".format(fc_out.shape))\n",
    "        sigmoid_out = self.sigmoid(fc_out)\n",
    "        sigmoid_out = sigmoid_out.view(batch_size, input.shape[1], -1)\n",
    "        #print(\"Sigmoid out shape : {}\".format(sigmoid_out.shape))\n",
    "        sigmoid_last = sigmoid_out[:, -1] # Final output of RNN\n",
    "        #print(\"Sigmoid last shape : {}\".format(sigmoid_last.shape))\n",
    "        return sigmoid_last, h\n",
    "    \n",
    "    def init_hidden (self, batch_size, device):         \n",
    "        weights = next(self.parameters()).data\n",
    "        h = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "             weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to run the training\n",
    "import numpy as np\n",
    "\n",
    "def cal_acc(probs, target):\n",
    "    # probs: probability that each image is labeled as 1\n",
    "    # target: ground truth label\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.argmax(probs, axis=-1)    \n",
    "        acc = torch.sum(prediction == target)\n",
    "        return acc.item() / len(target) * 100\n",
    "\n",
    "def train_one_pass_rnn(network, optim, device, criterion):\n",
    "  # Input: Network and Optimizer\n",
    "  # Output: Averge accuracy , Avergae loss in the pass\n",
    "    network.train()\n",
    "    acc_one_pass = []\n",
    "    loss_one_pass = []\n",
    "    for i, segment in enumerate(standardized_segments):\n",
    "        optim.zero_grad()\n",
    "        X = torch.tensor(segment).unsqueeze(dim=0).float().to(device)\n",
    "        y = torch.ones(X.size()[1])\n",
    "        y = torch.Tensor.new_full(y, y.size(), segment_labels[i][0], dtype=int, device=device, requires_grad=True)\n",
    "        out, h = network(X)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(loss)\n",
    "\n",
    "def train_one_pass_lstm(network, optim, device, criterion):\n",
    "    # Input: Network and Optimizer\n",
    "    # Output: Averge accuracy , Avergae loss in the pass\n",
    "    network.train()\n",
    "    \n",
    "    h = network.init_hidden(batch_size, device)\n",
    "    acc_one_pass = []\n",
    "    loss_one_pass = []\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.transpose(1,0).squeeze()\n",
    "        h = tuple([each.data for each in h])   \n",
    "        optim.zero_grad()\n",
    "        out, h = network(inputs)\n",
    "        loss = criterion(out.squeeze(), labels)\n",
    "        loss_one_pass.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(np.mean(loss_one_pass))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28, 14, 24, 12, 44, 29, 11, 16, 21, 15], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([46, 45, 32,  2, 11, 14, 17,  9, 26, 11], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([20, 30,  2, 34, 12,  2, 39, 33, 16,  1], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([19,  2,  2, 29, 34, 11, 13, 26, 44,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([30, 21, 24,  2,  5, 46, 14, 40,  1,  9], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([36, 19, 27, 14,  2, 11,  5,  8, 15,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([33,  2,  8,  9, 33,  6, 11, 37,  9, 20], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 12, 34, 27, 17, 32, 27,  9,  5, 34], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 15,  6,  2, 17,  2,  1,  3, 12, 33], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 8, 15, 28,  3, 17, 27, 45, 13,  6,  3], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "3.8306580781936646\n",
      "tensor([ 2, 16, 27, 24, 19, 11,  9,  6, 20, 27], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([33, 34, 33,  1,  1, 14,  2, 30,  2, 46], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 9,  2, 45, 14, 19, 17, 34, 34,  2,  2], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 6, 15, 28,  5, 11,  9,  8,  2,  1, 11], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 21,  8,  5, 39,  6, 17, 29, 12, 15], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([20, 33, 11,  3, 29,  8, 14, 36, 17, 13], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([30,  2, 44, 13,  2, 34, 14,  3, 40, 28], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([27, 24, 26, 26, 15,  5, 32, 46,  2,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([44, 14, 16, 33, 27,  9, 17,  6,  3, 45], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([12, 37, 21, 11, 32, 11, 15, 12,  9, 12], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "3.6873632192611696\n",
      "tensor([26, 17,  1, 11, 45, 19, 33, 11,  8,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14,  2,  9, 27,  2, 14,  9, 28, 44, 12], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 2,  2,  9, 39, 21, 14,  5, 14, 27, 11], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([12, 29, 26, 32, 17,  3,  2,  3, 12, 11], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([46,  3, 28, 34,  2,  2,  6,  1,  8, 36], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([29,  5, 33, 13,  6,  5,  8, 11, 20, 24], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([34, 45, 15, 16, 30,  9, 27, 24, 13,  2], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([11, 16, 44,  2, 46, 34, 14,  6, 30, 15], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([21, 33, 12, 34, 19, 15, 15, 27, 33, 17], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 20,  1,  9, 37, 40, 17,  2, 32,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "3.6263272285461428\n",
      "tensor([13, 14, 12, 15, 45, 11, 39,  2, 27,  2], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([15,  6, 11, 13,  6, 26, 33,  9,  5, 33], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([16,  2, 21, 36, 12, 16, 29, 12, 27, 33], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([12,  1, 34, 14, 19, 27,  5,  2,  1,  3], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 1, 34, 17,  9, 17, 27, 11,  8, 20, 24], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 5, 28,  2, 45,  3, 30,  2, 34, 19, 14], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([46, 34,  6, 32,  2, 26,  2,  9, 11, 15], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([44,  6, 46, 14, 15,  9, 17, 14, 24, 29], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([28,  3, 17,  2, 11, 40, 44, 21, 37, 14], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([32, 11, 30,  9, 20,  8,  6,  8, 33,  2], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "3.611875128746033\n",
      "tensor([16, 33, 11, 17,  2, 46, 33, 27, 44,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 3,  1, 21, 30, 34, 27, 29, 24,  5, 14], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([15, 17, 11,  9, 16, 19, 33, 15, 15, 28], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 12, 46, 26,  9, 34, 11,  6, 14, 45], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([11,  2, 29,  8,  9,  2, 37, 11,  9,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 2, 17, 28, 13,  6,  2, 36, 27, 20,  2], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([ 2, 40,  8, 34, 17,  3, 15, 13, 21,  9], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([24, 19, 12, 32,  2, 12,  3, 26, 34,  6], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([14, 14,  2,  2, 33, 27, 12,  1, 14, 32], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "tensor([45, 11, 39,  1, 30, 20, 44,  5,  5,  8], device='cuda:0')\n",
      "Sigmoid out shape : torch.Size([10, 300, 47])\n",
      "Sigmoid last shape : torch.Size([10, 47])\n",
      "3.601843476295471\n"
     ]
    }
   ],
   "source": [
    "#Run the training\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# Model paramters\n",
    "input_dim = 400 # number of features in each frame\n",
    "hidden_dim = 256\n",
    "output_dim = 47\n",
    "n_layers = 10\n",
    "    \n",
    "#net = myGruNet(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
    "#net = myRnn(input_dim, hidden_dim, output_dim).to(device)\n",
    "net = myLSTM(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()#nn.BCELoss()\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_one_pass_lstm(net, optimizer, device, criterion)\n",
    "\n",
    "# validation\n",
    "# net.eval()\n",
    "# valid_losses = []\n",
    "# v_h = net.init_hidden(batch_size, device)\n",
    "\n",
    "# for v_inputs, v_labels in valid_loader:\n",
    "#     v_inputs, v_labels = v_inputs.to(device), v_labels.to(device)\n",
    "#     print(v_inputs.shape)\n",
    "#     print(v_labels)\n",
    "#     v_h = tuple([each.data for each in v_h])\n",
    "\n",
    "#     v_output, v_h = net(v_inputs)\n",
    "#     print(v_output)\n",
    "#     v_loss = criterion(v_output.squeeze(), v_labels.float())\n",
    "#     valid_losses.append(v_loss.item())\n",
    "\n",
    "# print(\"Training Loss: {:.4f}\".format(v_loss.item()),\n",
    "#       \"Validation Loss: {:.4f}\".format(np.mean(valid_losses)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
