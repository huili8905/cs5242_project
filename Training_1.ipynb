{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Load the Training data and labels!!!\n",
      "Finish Load the Training data and labels!!!\n"
     ]
    }
   ],
   "source": [
    "from read_datasetBreakfast import load_data, read_mapping_dict, load_data_cust\n",
    "import os\n",
    "import torch\n",
    "import seaborn as sn\n",
    "\n",
    "COMP_PATH = 'C:\\\\Users\\\\cherl\\\\Desktop\\\\Masters\\\\CS5242 Neural Networks and Deep Learning\\\\Project'\n",
    "''' \n",
    "training to load train set\n",
    "test to load test set\n",
    "'''\n",
    "split = 'training'\n",
    "#split = 'test'\n",
    "train_split =  os.path.join(COMP_PATH, 'splits/train.split1.bundle') #Train Split\n",
    "test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
    "GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
    "DATA_folder =  os.path.join(COMP_PATH, 'data/') #Frame I3D features for all videos\n",
    "mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
    "\n",
    "actions_dict = read_mapping_dict(mapping_loc)\n",
    "if  split == 'training':\n",
    "    data_feat_train, data_labels = load_data(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
    "    data_feat_train_cust, data_labels_cust = load_data_cust(train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels\n",
    "if  split == 'test':\n",
    "    data_feat_test = load_data(test_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features only\n",
    "\n",
    "#'''\n",
    "#Write Code Below\n",
    "#Pointers\n",
    "#Need to load the segments.txt file for segments for test videos \n",
    "#Output the CSV in correct format as shown in Evaluation Section\n",
    "#Id corresponds to the segments in order. \n",
    "#Example - 30-150 = Id 0\n",
    "#          150-428 = Id 1\n",
    "#          428-575 = Id 2\n",
    "#Category is the Class of the Predicted Action\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 28\n",
      "Number of Training Data Labels: 28\n",
      "Size of Training Data #0: torch.Size([743, 400])\n",
      "743\n",
      "Testing Data not loaded\n"
     ]
    }
   ],
   "source": [
    "#Print info on the data\n",
    "print(\"Number of Training Data: {}\".format(len(data_feat_train)))\n",
    "print(\"Number of Training Data Labels: {}\".format(len(data_labels)))\n",
    "print(\"Size of Training Data #0: {}\".format(data_feat_train[0].size()))\n",
    "#print(data_feat_train[0][0])\n",
    "print(len(data_labels_cust[0]))\n",
    "#Testing Data\n",
    "try:\n",
    "    print(\"Number of Test Data: {}\".format(len(data_feat_test)))\n",
    "    print(\"% of Training Data: {}\".format(len(data_feat_test)/(len(data_feat_train)+len(data_feat_test))*100))\n",
    "except NameError:\n",
    "    print(\"Testing Data not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [6], [5], [2], [9], [8], [11], [12], [14], [13], [15], [19], [20], [21], [2], [24], [11], [26], [2], [27], [17], [27], [28], [14], [29], [30], [32], [34], [33], [34], [33], [34], [33], [34], [32], [33], [36], [37], [39], [40], [16], [17], [11], [12], [44], [14], [15], [6], [46], [45], [9], [1], [2], [3], [6], [5], [2], [9], [8], [11], [12], [14], [13], [15], [19], [20], [21], [2], [24], [11], [26], [2], [27], [17], [27], [28], [14], [29], [30], [16], [17], [11], [12], [44], [14], [15], [6], [46], [45], [9], [1], [2], [3], [6], [5], [2], [9], [8], [11], [12], [14], [13], [15], [19], [20], [21], [2], [24], [11], [26], [2], [27], [17], [27], [28], [14], [29], [30], [32], [34], [33], [34], [33], [34], [33], [34], [32], [33], [36], [37], [39], [40], [16], [17], [11], [12], [44], [14], [15], [6], [46], [45], [9]]\n"
     ]
    }
   ],
   "source": [
    "#Preparing the data by splitting video into segments\n",
    "segments = []\n",
    "segment_labels = []\n",
    "for i, video in enumerate(data_feat_train):\n",
    "    frame_num = 0\n",
    "    while frame_num < len(video):\n",
    "        #Skip SIL frames\n",
    "        if data_labels_cust[i][frame_num] > 0:\n",
    "            start_index = frame_num # start index of segment\n",
    "            end_index = frame_num # end index of segment\n",
    "            start_label = data_labels_cust[i][frame_num] # label of segment\n",
    "            for index in range(start_index + 1, len(video)):\n",
    "                if data_labels_cust[i][index] == start_label:\n",
    "                    frame_num=index + 1\n",
    "                    end_index=index\n",
    "                else:\n",
    "                    frame_num=index + 1\n",
    "                    break\n",
    "            segment = video[start_index:end_index]\n",
    "            segments.append(segment)\n",
    "            segment_label = []\n",
    "            segment_label.append(start_label)\n",
    "            segment_labels.append(segment_label)\n",
    "            #print(segment.size())\n",
    "            #print(\"start {}, end {}\".format(start_index, end_index))\n",
    "        else:\n",
    "            frame_num += 1\n",
    "print(segment_labels)\n",
    "\n",
    "#Making all the segments equal length\n",
    "standardized_segments = []\n",
    "target_segment_length = 300 # Standard length to convert all segments to. Tune as needed.\n",
    "\n",
    "for segment in segments:\n",
    "    if len(segment) > target_segment_length:\n",
    "        # Truncate segment\n",
    "        standardized_segment = segment[0:target_segment_length]\n",
    "        standardized_segments.append(standardized_segment)\n",
    "    elif len(segment) == target_segment_length:\n",
    "        standardized_segment = segment\n",
    "        standardized_segments.append(standardized_segment)\n",
    "    else:\n",
    "        # Pad segment\n",
    "        standardized_segment = torch.zeros(target_segment_length, 400)\n",
    "        standardized_segment[0:len(segment)] = segment\n",
    "        standardized_segments.append(standardized_segment)\n",
    "    #print(standardized_segment.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Define the neural network modules\n",
    "\n",
    "class mynet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mynet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 10, stride=5).double()\n",
    "        self.pool = nn.MaxPool2d(5, stride=5).double()\n",
    "        self.fc1 = nn.Linear(target_segment_length * 16, 47).double()\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "class myGruNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(myGruNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    #Initialize the hidden layer\n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden\n",
    "\n",
    "class myRnn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size, n_layers=1):\n",
    "        super(myRnn, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "         \n",
    "        batch_size = input.size(0)\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(input, hidden)\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to run the training\n",
    "def cal_acc(probs, target):\n",
    "    # probs: probability that each image is labeled as 1\n",
    "    # target: ground truth label\n",
    "    with torch.no_grad():\n",
    "      prediction = torch.argmax(probs, axis=-1)    \n",
    "      acc = torch.sum(prediction == target)\n",
    "    return acc.item() / len(target) * 100\n",
    "\n",
    "def train_one_pass_rnn(network, optim, device, criterion):\n",
    "  # Input: Network and Optimizer\n",
    "  # Output: Averge accuracy , Avergae loss in the pass\n",
    "  network.train()\n",
    "  acc_one_pass = []\n",
    "  loss_one_pass = []\n",
    "  for i, segment in enumerate(standardized_segments):\n",
    "    optim.zero_grad()\n",
    "    X = torch.tensor(segment).unsqueeze(dim=0).float().to(device)\n",
    "    y = torch.ones(X.size()[1])\n",
    "    y = torch.Tensor.new_full(y, y.size(), segment_labels[i][0], dtype=int, device=device, requires_grad=True)\n",
    "    out, h = network(X)\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cherl\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.0703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.1781, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.2726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6614, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4600, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.4517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0315, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.3108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8839, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.9165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.7802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2917, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Run the training\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Model paramters\n",
    "input_dim = 400\n",
    "hidden_dim = 256\n",
    "output_dim = 47\n",
    "n_layers = 2\n",
    "    \n",
    "#net = myGruNet(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
    "net = myRnn(input_dim, hidden_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "train_one_pass_rnn(net, optimizer, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
